{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3fd1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "igfold = 2\n",
    "os.system('mkdir -p ./data_folds/fold_' + str(igfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cdb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 13:26:45 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    43W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    44W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd54a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c383e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = False\n",
    "path = '../data/'\n",
    "type_weight = {0:1, 1:6, 2:3}\n",
    "no_files = 5\n",
    "path = '../../data/'\n",
    "    \n",
    "df_type = cudf.DataFrame({\n",
    "    'type': ['clicks', 'carts', 'orders'],\n",
    "    'type_': [0, 1, 2]\n",
    "})\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fc5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./data/\n",
    "!mkdir -p ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658f63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(\n",
    "    glob.glob('../../data/' + '/train/interim/*.parquet')\n",
    ")\n",
    "files_split = [glob.glob('../../data/test.parquet')] + [glob.glob('./data/xgb_train_x.parquet')] + list_in_chunks(files, no_chunks=len(files)//no_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e11fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356748\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "sessions = pickle.load(open('./data/sessions_eval.pickle', 'rb'))\n",
    "if igfold == 0:\n",
    "    sess_eval = sessions[0]+sessions[1]\n",
    "elif igfold == 1:\n",
    "    sess_eval = sessions[2]+sessions[3]\n",
    "elif igfold == 2:\n",
    "    sess_eval = sessions[4]+sessions[5]\n",
    "elif igfold == 3:\n",
    "    sess_eval = sessions[6]+sessions[7]\n",
    "elif igfold == 4:\n",
    "    sess_eval = sessions[8]+sessions[9]\n",
    "print(len(sess_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9e0999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29893f25",
   "metadata": {},
   "source": [
    "### 2)  \"Buy2Buy\" Co-visitation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f83f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/xgb_train_x.parquet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:37,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for e, file in tqdm(enumerate(files_split)):\n",
    "    df = cudf.read_parquet(file)\n",
    "    df = df.merge(\n",
    "        df_type,\n",
    "        how='left',\n",
    "        on='type'\n",
    "    )\n",
    "    if any([True for x in file if 'xgb_train_x.parquet' in x]):\n",
    "        print(file)\n",
    "        df = df[df['session'].isin(sess_eval)]\n",
    "    else:\n",
    "        df = df.loc[~(df['session'].isin(sess_eval))]\n",
    "\n",
    "    df['session'] = df['session'].astype('int32')\n",
    "    df['aid'] = df['aid'].astype('int32')\n",
    "    df.ts = (df.ts/1000).astype('int32')\n",
    "    df.drop(['type'], axis=1, inplace=True)\n",
    "    df = df.rename(columns={'type_': 'type'})\n",
    "    df = df.loc[df['type'].isin([1,2])]\n",
    "    df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "    # USE TAIL OF SESSION\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['n'] = df.groupby('session').cumcount()\n",
    "    df = df.loc[df.n<30].drop('n',axis=1)\n",
    "    df = df.merge(\n",
    "        df, \n",
    "        how='left',\n",
    "        on='session'\n",
    "    )\n",
    "    gc.collect()\n",
    "    df = df.loc[ ((df.ts_x - df.ts_y).abs()< 14 * 24 * 60 * 60) & (df.aid_x != df.aid_y) ]\n",
    "    gc.collect()\n",
    "    # ASSIGN WEIGHTS\n",
    "    df = df[['session', 'aid_x', 'aid_y','type_y']].drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    df['wgt'] = 1\n",
    "    df = df[['aid_x','aid_y','wgt']]\n",
    "    df.wgt = df.wgt.astype('float32')\n",
    "    df = df.groupby(['aid_x','aid_y']).wgt.sum()\n",
    "    out.append(df.to_pandas())\n",
    "    del df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f2dee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.concat([cudf.from_pandas(x) for x in out])\n",
    "gc.collect()\n",
    "df = df.reset_index().groupby(['aid_x','aid_y']).wgt.sum()\n",
    "gc.collect()\n",
    "df = df.reset_index()\n",
    "df = df.sort_values(['aid_x','wgt'],ascending=[True,False])\n",
    "df = df.reset_index(drop=True)\n",
    "gc.collect()\n",
    "df['n'] = df.groupby('aid_x').aid_y.cumcount()\n",
    "df = df.loc[df.n<50]\n",
    "df.to_parquet('./data_folds/fold_' + str(igfold) + '/top_15_buy2buy_v3.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50a57d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del out, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4ce6d",
   "metadata": {},
   "source": [
    "### Generate Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8d5ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 13:27:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    70W / 163W |    690MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    44W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95c0a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20ec88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(df, co, prefix, treshhold=2, treshhold_topn=15):\n",
    "    df = df.merge(\n",
    "        co[co['n']<treshhold_topn][['aid', 'cand', 'wgt']],\n",
    "        how='left',\n",
    "        on='aid'\n",
    "    )\n",
    "    df['wgt2'] = df['wgt']*df['score']\n",
    "    df['wgt_cl'] = (df['type']=='clicks').astype('int8')*df['wgt']\n",
    "    df['wgt_ca'] = (df['type']=='carts').astype('int8')*df['wgt']\n",
    "    df['wgt_or'] = (df['type']=='orders').astype('int8')*df['wgt']\n",
    "    df.drop(['aid', 'ts', 'type'], axis=1, inplace=True)\n",
    "    df = df.groupby(['session', 'cand']).agg({\n",
    "        'dummy': 'sum',\n",
    "        'rank': 'min',\n",
    "        'wgt': 'sum',\n",
    "        'wgt2': 'sum',\n",
    "        'wgt_cl': 'sum',\n",
    "        'wgt_ca': 'sum',\n",
    "        'wgt_or': 'sum'\n",
    "    }).reset_index()\n",
    "    df.columns = [\n",
    "        'session', 'cand', \n",
    "        prefix+'_num_' + str(treshhold_topn),\n",
    "        prefix+'_rank_min_'+ str(treshhold_topn), \n",
    "        prefix+'_wgt_' + str(treshhold_topn),\n",
    "        prefix+'_wgt_2_'+ str(treshhold_topn), \n",
    "        prefix+'_wgt_cl_'+ str(treshhold_topn), \n",
    "        prefix+'_wgt_ca_'+ str(treshhold_topn), \n",
    "        prefix+'_wgt_or_'+ str(treshhold_topn)\n",
    "    ]\n",
    "    return(df)\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec211bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_main = 'b2b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fca54293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2b train 15\n",
      "b2b sub 15\n",
      "caco_b2b train 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cupy/_creation/from_data.py:76: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return _core.array(a, dtype, False, order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caco_b2b sub 15\n"
     ]
    }
   ],
   "source": [
    "for type_filter in [[[], ''], [['carts', 'orders'], 'caco']]:\n",
    "    for dataset in ['train', 'sub']:\n",
    "        for treshhold_topn in [15]:\n",
    "            if len(type_filter[0])>0:\n",
    "                prefix = type_filter[1] + '_' + prefix_main\n",
    "            else:\n",
    "                prefix = prefix_main\n",
    "            print(prefix, dataset, treshhold_topn)\n",
    "            os.system('mkdir -p ./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn))\n",
    "            co = cudf.read_parquet('./data_folds/fold_' + str(igfold) + '/top_15_buy2buy_v3.parquet')\n",
    "            co.columns = ['aid', 'cand', 'wgt', 'n']\n",
    "            if dataset == 'train':\n",
    "                df = cudf.read_parquet('./data/xgb_train_x.parquet')\n",
    "                df = df[df['session'].isin(sess_eval)]\n",
    "            else:\n",
    "                df = cudf.read_parquet('../../data/test.parquet')\n",
    "            if len(type_filter[0])>0:\n",
    "                df = df[df['type'].isin(type_filter)]\n",
    "            df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "            df['dummy'] = 1\n",
    "            df['rank'] = df.groupby(['session']).dummy.cumsum()\n",
    "            df['score'] = 1/df['rank']\n",
    "            session_lists = list_in_chunks(df['session'].drop_duplicates().to_pandas().values.tolist(), no_chunks=10)\n",
    "            out = []\n",
    "            for session_list in session_lists:\n",
    "                df_tmp = df[df['session'].isin(session_list)]\n",
    "                df_tmp = get_candidates(df_tmp, co, prefix, treshhold=2, treshhold_topn=treshhold_topn)\n",
    "                out.append(df_tmp)\n",
    "            df = cudf.concat(out)\n",
    "            df['session'] = df['session'].astype('int32')\n",
    "            df['cand'] = df['cand'].astype('int32')\n",
    "            df[prefix + '_num_'+ str(treshhold_topn)] = df[prefix + '_num_'+ str(treshhold_topn)].astype('int16')\n",
    "            df[prefix + '_rank_min_'+ str(treshhold_topn)] = df[prefix + '_rank_min_'+ str(treshhold_topn)].astype('int16')\n",
    "            df[prefix + '_wgt_'+ str(treshhold_topn)] = df[prefix + '_wgt_'+ str(treshhold_topn)].astype('int16')\n",
    "            df[prefix + '_wgt_2_'+ str(treshhold_topn)] = df[prefix + '_wgt_2_'+ str(treshhold_topn)].astype('float32')\n",
    "            df[prefix + '_wgt_cl_'+ str(treshhold_topn)] = df[prefix + '_wgt_cl_'+ str(treshhold_topn)].astype('int16')\n",
    "            df[prefix + '_wgt_ca_'+ str(treshhold_topn)] = df[prefix + '_wgt_ca_'+ str(treshhold_topn)].astype('int16')\n",
    "            df[prefix + '_wgt_or_'+ str(treshhold_topn)] = df[prefix + '_wgt_or_'+ str(treshhold_topn)].astype('int16')\n",
    "            df.to_parquet('./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn) + '/cand.parquet')\n",
    "            del df\n",
    "            gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
