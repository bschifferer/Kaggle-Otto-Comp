{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3fd1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "igfold = 4\n",
    "os.system('mkdir -p ./data_folds/fold_' + str(igfold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cdb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 13:25:08 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    77W / 163W |   1174MiB / 32510MiB |     69%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    46W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd54a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c383e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = False\n",
    "path = '../data/'\n",
    "type_weight = {0:1, 1:6, 2:3}\n",
    "no_files = 3\n",
    "path = '../../data/'\n",
    "    \n",
    "df_type = cudf.DataFrame({\n",
    "    'type': ['clicks', 'carts', 'orders'],\n",
    "    'type_': [0, 1, 2]\n",
    "})\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fc5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./data/\n",
    "!mkdir -p ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658f63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(\n",
    "    glob.glob('../../data/' + '/train/interim/*.parquet')\n",
    ")\n",
    "files_split = [glob.glob('../../data/test.parquet')] + [glob.glob('./data/xgb_train_x.parquet')] + list_in_chunks(files, no_chunks=len(files)//no_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9e0999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d5b940d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356746\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "sessions = pickle.load(open('./data/sessions_eval.pickle', 'rb'))\n",
    "if igfold == 0:\n",
    "    sess_eval = sessions[0]+sessions[1]\n",
    "elif igfold == 1:\n",
    "    sess_eval = sessions[2]+sessions[3]\n",
    "elif igfold == 2:\n",
    "    sess_eval = sessions[4]+sessions[5]\n",
    "elif igfold == 3:\n",
    "    sess_eval = sessions[6]+sessions[7]\n",
    "elif igfold == 4:\n",
    "    sess_eval = sessions[8]+sessions[9]\n",
    "print(len(sess_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab4cb0",
   "metadata": {},
   "source": [
    "### 3) \"Clicks\" Co-visitation Matrix - Time Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f6a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b7dcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/xgb_train_x.parquet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:52,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/data/tmp_1/split/split_9.parquet\n",
      "/tmp/data/tmp_1/split/split_36.parquet\n",
      "/tmp/data/tmp_1/split/split_39.parquet\n",
      "/tmp/data/tmp_1/split/split_25.parquet\n",
      "/tmp/data/tmp_1/split/split_24.parquet\n",
      "/tmp/data/tmp_1/split/split_6.parquet\n",
      "/tmp/data/tmp_1/split/split_28.parquet\n",
      "/tmp/data/tmp_1/split/split_35.parquet\n",
      "/tmp/data/tmp_1/split/split_11.parquet\n",
      "/tmp/data/tmp_1/split/split_14.parquet\n",
      "/tmp/data/tmp_1/split/split_32.parquet\n",
      "/tmp/data/tmp_1/split/split_44.parquet\n",
      "/tmp/data/tmp_1/split/split_31.parquet\n",
      "/tmp/data/tmp_1/split/split_42.parquet\n",
      "/tmp/data/tmp_1/split/split_12.parquet\n",
      "/tmp/data/tmp_1/split/split_19.parquet\n",
      "/tmp/data/tmp_1/split/split_34.parquet\n",
      "/tmp/data/tmp_1/split/split_23.parquet\n",
      "/tmp/data/tmp_1/split/split_16.parquet\n",
      "/tmp/data/tmp_1/split/split_37.parquet\n",
      "/tmp/data/tmp_1/split/split_30.parquet\n",
      "/tmp/data/tmp_1/split/split_22.parquet\n",
      "/tmp/data/tmp_1/split/split_29.parquet\n",
      "/tmp/data/tmp_1/split/split_27.parquet\n",
      "/tmp/data/tmp_1/split/split_13.parquet\n",
      "/tmp/data/tmp_1/split/split_20.parquet\n",
      "/tmp/data/tmp_1/split/split_0.parquet\n",
      "/tmp/data/tmp_1/split/split_18.parquet\n",
      "/tmp/data/tmp_1/split/split_7.parquet\n",
      "/tmp/data/tmp_1/split/split_3.parquet\n",
      "/tmp/data/tmp_1/split/split_2.parquet\n",
      "/tmp/data/tmp_1/split/split_5.parquet\n",
      "/tmp/data/tmp_1/split/split_17.parquet\n",
      "/tmp/data/tmp_1/split/split_10.parquet\n",
      "/tmp/data/tmp_1/split/split_21.parquet\n",
      "/tmp/data/tmp_1/split/split_40.parquet\n",
      "/tmp/data/tmp_1/split/split_4.parquet\n",
      "/tmp/data/tmp_1/split/split_1.parquet\n",
      "/tmp/data/tmp_1/split/split_41.parquet\n",
      "/tmp/data/tmp_1/split/split_33.parquet\n",
      "/tmp/data/tmp_1/split/split_15.parquet\n",
      "/tmp/data/tmp_1/split/split_8.parquet\n",
      "/tmp/data/tmp_1/split/split_43.parquet\n",
      "/tmp/data/tmp_1/split/split_26.parquet\n",
      "./data/xgb_train_x.parquet\n",
      "./data/xgb_train_x.parquet\n"
     ]
    }
   ],
   "source": [
    "for ty1 in [1]:\n",
    "    os.system('rm -r /tmp/data/tmp_1')\n",
    "    os.system('mkdir -p /tmp/data/tmp_1/split')\n",
    "    if ty1 == 0:\n",
    "        ty2s = [2]\n",
    "    else:\n",
    "        ty2s = [2]\n",
    "    for ty2 in ty2s:\n",
    "        print(ty1, ty2)\n",
    "        out = []\n",
    "        for e, file in tqdm(enumerate(files_split)):\n",
    "            df = cudf.read_parquet(file)\n",
    "            df = df.merge(\n",
    "                df_type,\n",
    "                how='left',\n",
    "                on='type'\n",
    "            )\n",
    "            if any([True for x in file if 'xgb_train_x.parquet' in x]):\n",
    "                print(file)\n",
    "                df = df[df['session'].isin(sess_eval)]\n",
    "            else:\n",
    "                df = df.loc[~(df['session'].isin(sess_eval))]\n",
    "            if ty1 == 0 and ty2 == 1:\n",
    "                df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "                df['ts_2'] = df.groupby(['session']).ts.shift(1)\n",
    "                df['diff_'] = df['ts_2']-df['ts']\n",
    "                df['diff_'] = ((df['diff_']/1000)>(2*24*60*60)).fillna(0).astype('int8')\n",
    "                df['new_session'] = df.groupby(['session']).diff_.cumsum()\n",
    "                df.drop(['ts_2', 'diff_'], axis=1, inplace=True)\n",
    "                df['session'] = df['session']*100+df['new_session']\n",
    "                df.drop(['new_session'], axis=1, inplace=True)\n",
    "\n",
    "            df['session'] = df['session'].astype('int32')\n",
    "            df['aid'] = df['aid'].astype('int32')\n",
    "            df.ts = (df.ts/1000).astype('int32')\n",
    "            df.drop(['type'], axis=1, inplace=True)\n",
    "            df = df.rename(columns={'type_': 'type'})\n",
    "            \n",
    "            df = df.sort_values(['session','ts'],ascending=[True,False])\n",
    "            df = df.reset_index(drop=True)\n",
    "            df['n'] = df.groupby('session').cumcount()\n",
    "            df['n'] = df['n'].astype('int16')\n",
    "            \n",
    "            df_r = df[df['type']==ty1].reset_index(drop=True)\n",
    "            df_l = df[df['type']==ty2].reset_index(drop=True)\n",
    "            \n",
    "            del df\n",
    "            gc.collect()\n",
    "            \n",
    "            df = df_r.merge(\n",
    "                df_l[['session', 'aid', 'ts', 'n']], \n",
    "                how='left',\n",
    "                on='session'\n",
    "            )\n",
    "            df = df[~df['aid_y'].isna()]\n",
    "            \n",
    "            del df_r, df_l\n",
    "            gc.collect()\n",
    "            \n",
    "            df['diff_time'] = (df['ts_x']-df['ts_y']).abs()\n",
    "            df.drop(['ts_x', 'ts_y'], axis=1, inplace=True)\n",
    "            df['w_time'] = 1/cupy.log(df['diff_time']+2)\n",
    "            df.drop(['diff_time'], inplace=True, axis=1)\n",
    "\n",
    "            df['diff_pos'] = (df['n_x']-df['n_y']).abs()\n",
    "            df['w_pos'] = 1/cupy.log(df['diff_pos']+2)\n",
    "            df.drop(['diff_pos'], inplace=True, axis=1)\n",
    "\n",
    "            df['wgt'] = df['w_time']*df['w_pos']\n",
    "            \n",
    "            df = df[['session', 'aid_x', 'aid_y', 'wgt']].groupby(['session', 'aid_x', 'aid_y']).agg(['sum', 'count'])\n",
    "            df = df.reset_index()\n",
    "            \n",
    "            df.columns = ['session', 'aid_x', 'aid_y', 'wgt_sum', 'wgt_count']\n",
    "            \n",
    "            df = df.groupby(['aid_x', 'aid_y']).agg({\n",
    "                'wgt_sum': 'sum',\n",
    "                'wgt_count': 'sum',\n",
    "                'session': 'count'\n",
    "            })\n",
    "            df = df.reset_index()\n",
    "            df.columns = ['aid_x', 'aid_y', 'wgt_sum', 'wgt_count', 'count']\n",
    "            df.to_parquet('/tmp/data/tmp_1/split/split_' + str(e) + '.parquet')\n",
    "            del df\n",
    "            gc.collect()\n",
    "        \n",
    "        files_split1 = glob.glob('/tmp/data/tmp_1/split/split_*.parquet')\n",
    "        df = cudf.read_parquet(files_split1[0])\n",
    "        for iifile, file in enumerate(files_split1[1:]):\n",
    "            print(file)\n",
    "            df2 = cudf.read_parquet(file)\n",
    "            df = cudf.concat([\n",
    "                df,\n",
    "                df2\n",
    "            ])\n",
    "            gc.collect()\n",
    "            df = df.groupby(['aid_x','aid_y']).sum()\n",
    "            df = df.reset_index()\n",
    "            if ty1==0 and ty2==1:\n",
    "                if iifile==30:\n",
    "                    print('Filter')\n",
    "                    df = df[df['count']>1]\n",
    "            del df2\n",
    "            gc.collect()\n",
    "        \n",
    "        df = df[df['count']>1]\n",
    "        gc.collect()\n",
    "        files_aid = sorted(glob.glob('../../data/' + '/train/interim/*.parquet')) + glob.glob('../../data/test.parquet') + glob.glob('./data/xgb_train_x.parquet')\n",
    "        out = []\n",
    "        for file in files_aid:\n",
    "            df_tmp = cudf.read_parquet(file)\n",
    "            if 'xgb_train_x.parquet' in file:\n",
    "                print(file)\n",
    "                df_tmp = df_tmp[df_tmp['session'].isin(sess_eval)]\n",
    "            else:\n",
    "                df_tmp = df_tmp[~(df_tmp['session'].isin(sess_eval))]\n",
    "            out.append(df_tmp)\n",
    "        df_aid = cudf.concat(out)\n",
    "        del out\n",
    "        gc.collect()\n",
    "        \n",
    "        df_aid = df_aid.merge(\n",
    "            df_type,\n",
    "            how='left',\n",
    "            on='type'\n",
    "        )\n",
    "        df_aid = df_aid[df_aid['type_']==ty1]\n",
    "        df_aid = df_aid.drop_duplicates(['session', 'aid'])\n",
    "        df_aid = df_aid['aid'].value_counts().reset_index()\n",
    "        df_aid = df_aid.reset_index()\n",
    "        df_aid.columns = ['aid_', 'aid', 'count']\n",
    "        df_aid.drop(['aid_'], inplace=True, axis=1)\n",
    "        df_aid.columns = ['aid_x', 'count_x']\n",
    "        df = df.merge(\n",
    "            df_aid,\n",
    "            how='left',\n",
    "            on=['aid_x']\n",
    "        )\n",
    "        \n",
    "        files_aid = sorted(glob.glob('../../data/' + '/train/interim/*.parquet')) + glob.glob('../../data/test.parquet') + glob.glob('./data/xgb_train_x.parquet')\n",
    "        out = []\n",
    "        for file in files_aid:\n",
    "            df_tmp = cudf.read_parquet(file)\n",
    "            if 'xgb_train_x.parquet' in file:\n",
    "                print(file)\n",
    "                df_tmp = df_tmp[df_tmp['session'].isin(sess_eval)]\n",
    "            else:\n",
    "                df_tmp = df_tmp[~(df_tmp['session'].isin(sess_eval))]\n",
    "            out.append(df_tmp)\n",
    "        df_aid = cudf.concat(out)\n",
    "        del out\n",
    "        gc.collect()\n",
    "        df_aid = df_aid.merge(\n",
    "            df_type,\n",
    "            how='left',\n",
    "            on='type'\n",
    "        )\n",
    "        df_aid = df_aid[df_aid['type_']==ty2]\n",
    "        df_aid = df_aid.drop_duplicates(['session', 'aid'])\n",
    "        df_aid = df_aid['aid'].value_counts().reset_index()\n",
    "        df_aid = df_aid.reset_index()\n",
    "        df_aid.columns = ['aid_', 'aid', 'count']\n",
    "        df_aid.drop(['aid_'], inplace=True, axis=1)\n",
    "        df_aid.columns = ['aid_y', 'count_y']\n",
    "        df = df.merge(\n",
    "            df_aid,\n",
    "            how='left',\n",
    "            on=['aid_y']\n",
    "        )\n",
    "        \n",
    "        df['wgt_sum_2'] = df['wgt_sum']/(cupy.sqrt((df['count_x'].fillna(0)+1).values)*cupy.sqrt((df['count_y'].fillna(0)+1).values))\n",
    "        df['wgt_prob'] = df['count']/cupy.sqrt((df['count_x'].fillna(0)+1).values)\n",
    "        df['wgt_prob_2'] = df['count']/(cupy.sqrt((df['count_x'].fillna(0)+1).values)*cupy.sqrt((df['count_y'].fillna(0)+1).values))\n",
    "        df[['aid_x', 'aid_y', 'wgt_sum', 'wgt_sum_2', 'wgt_prob', 'wgt_prob_2', 'count']].to_parquet(\n",
    "            './data_folds/fold_' + str(igfold) + '/top_20_wt_' + str(ty1) + '_' + str(ty2) + '.parquet'\n",
    "\n",
    "        )\n",
    "        del df\n",
    "        del df_aid\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa4ce6d",
   "metadata": {},
   "source": [
    "### Generate Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d5ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 13:27:26 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    50W / 163W |   8442MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    70W / 163W |    754MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c0a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ec88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(df, co, prefix, treshhold=2, treshhold_topn=15):\n",
    "    df = df.merge(\n",
    "        co[co['n']<treshhold_topn],\n",
    "        how='left',\n",
    "        on='aid'\n",
    "    )\n",
    "    df.drop(['n'], axis=1, inplace=True)\n",
    "    for col in ['wgt_sum', 'wgt_sum_2', 'wgt_prob', 'wgt_prob_2', 'count']:\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "    for col in ['wgt_sum_2', 'wgt_prob', 'count']:\n",
    "        df[col + '_m'] = df[col].values\n",
    "        df[col + '_2'] = df[col]*df['score']\n",
    "    df.drop(['aid', 'ts', 'type'], axis=1, inplace=True)\n",
    "    \n",
    "    agg_dict = {\n",
    "        'dummy': 'sum'\n",
    "    }\n",
    "    for col in ['wgt_sum_2', 'wgt_prob', 'count']:\n",
    "        agg_dict[col] = 'sum'\n",
    "        #agg_dict[col + '_m'] = 'max'\n",
    "        agg_dict[col + '_2'] = 'sum'\n",
    "    \n",
    "    df = df.groupby(['session', 'cand']).agg(agg_dict).reset_index()\n",
    "    df.columns = ['session', 'cand'] + [prefix + '_' + x for x in df.columns if x not in ['session', 'cand']]\n",
    "    return(df)\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)\n",
    "\n",
    "def add_log_recency_score(df):\n",
    "    linear_interpolation = 0.1 + ((1-0.1) / (df['session_len']-1)) * (df['session_len']-df['rank'])\n",
    "    df['score'] = (2 ** linear_interpolation - 1).fillna(1.0)\n",
    "    return df\n",
    "\n",
    "df_type = cudf.DataFrame({\n",
    "    'type': ['clicks', 'carts', 'orders'],\n",
    "    'type_': [0, 1, 2]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86c715ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainprefix = 'weighted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "357f2c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 20\n",
      "sub 20\n"
     ]
    }
   ],
   "source": [
    "for ty1 in [1]:\n",
    "    if ty1 == 0:\n",
    "        ty2s = [1, 2]\n",
    "    else:\n",
    "        ty2s = [2]\n",
    "    for ty2 in ty2s:\n",
    "        prefix = mainprefix + '_' + str(ty1) + '_' + str(ty2)\n",
    "        for dataset in ['train', 'sub']:\n",
    "            for treshhold_topn in [20]:\n",
    "                print(dataset, treshhold_topn)\n",
    "                os.system('mkdir -p ./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn))\n",
    "                co = cudf.read_parquet('./data_folds/fold_' + str(igfold) + '/top_20_wt_' + str(ty1) + '_' + str(ty2) + '.parquet')\n",
    "                co = co.sort_values(['aid_x','wgt_sum_2'],ascending=[True,False])\n",
    "                co = co.reset_index(drop=True)\n",
    "                co['n'] = co.groupby('aid_x').aid_y.cumcount()\n",
    "                co.columns = ['aid', 'cand', 'wgt_sum', 'wgt_sum_2', 'wgt_prob', 'wgt_prob_2', 'count', 'n']\n",
    "                if dataset == 'train':\n",
    "                    df = cudf.read_parquet('./data/xgb_train_x.parquet')\n",
    "                    df = df[df['session'].isin(sess_eval)]\n",
    "                else:\n",
    "                    df = cudf.read_parquet('../../data/test.parquet')\n",
    "                df = df.merge(\n",
    "                    df_type,\n",
    "                    how='left',\n",
    "                    on='type'\n",
    "                )\n",
    "                df.drop(['type'], axis=1, inplace=True)\n",
    "                df = df.rename(columns={'type_': 'type'})\n",
    "                df = df[df['type']==ty1]\n",
    "                df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "                df['dummy'] = 1\n",
    "                df['rank'] = df.groupby(['session']).dummy.cumsum()\n",
    "                df = df.merge(\n",
    "                    df[['session']].groupby(['session']).size().reset_index().rename(columns={0: 'session_len'}),\n",
    "                    how='left',\n",
    "                    on=['session']\n",
    "                )\n",
    "                df['session_len'] = df['session_len'].astype('int16')\n",
    "                df = add_log_recency_score(df)\n",
    "                session_lists = list_in_chunks(df['session'].drop_duplicates().to_pandas().values.tolist(), no_chunks=10)\n",
    "                out = []\n",
    "                for session_list in session_lists:\n",
    "                    df_tmp = df[df['session'].isin(session_list)]\n",
    "                    df_tmp = get_candidates(df_tmp, co, prefix, treshhold=2, treshhold_topn=treshhold_topn)\n",
    "                    out.append(df_tmp)\n",
    "                df = cudf.concat(out)\n",
    "                del out\n",
    "                gc.collect()\n",
    "                df['session'] = df['session'].astype('int32')\n",
    "                df['cand'] = df['cand'].astype('int32')\n",
    "                df.to_parquet('./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn) + '/cand.parquet')\n",
    "                del df\n",
    "                gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f3136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f361d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
