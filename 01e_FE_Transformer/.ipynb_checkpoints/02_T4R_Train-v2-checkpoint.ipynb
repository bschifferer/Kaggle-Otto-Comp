{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e49d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchmetrics==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5b254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (AvgPrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (AvgPrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers4rec import torch as tr\n",
    "\n",
    "from merlin_standard_lib import Schema\n",
    "import torch \n",
    "\n",
    "from custom_t4r import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3439a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTabularSequenceFeatures(tr.TabularSequenceFeatures):\n",
    "    def forward(self, inputs, training=False, testing=False, **kwargs):\n",
    "        self.to_merge.categorical_module.type_seq = inputs['type_']\n",
    "        outputs = super(CustomTabularSequenceFeatures, self).forward(inputs, training=training, testing=testing, **kwargs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1192c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training Param\n",
    "# batch_size = 1024\n",
    "# lr = 0.0005\n",
    "# lr_scheduler = 'constant' # cosine\n",
    "# num_train_epochs = 1\n",
    "# using_test = True\n",
    "# using_type = True\n",
    "# bl_shuffle = True\n",
    "\n",
    "# # Transformer Architecture\n",
    "# d_model = 64\n",
    "# n_head = 8\n",
    "# n_layer = 3\n",
    "# proj_num = 2\n",
    "# act_mlp = torch.nn.ReLU\n",
    "# act_mlp = None\n",
    "\n",
    "# # Next Item Prediction\n",
    "# item_correction = True\n",
    "# neg_factor=1\n",
    "# label_smoothing=0.0\n",
    "# temperature=1.0\n",
    "# remove_false_neg = False\n",
    "# item_correction_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47122070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#      'batch_size': 1024,\n",
    "#      'lr': 0.0005,\n",
    "#      'lr_scheduler': 'constant',\n",
    "#      'num_train_epochs': 1,\n",
    "#      'using_test': False,\n",
    "#      'using_type': True,\n",
    "#      'bl_shuffle': False,\n",
    "#      'masking': 'mlm',\n",
    "#      'd_model': 256,\n",
    "#      'n_head': 16,\n",
    "#      'n_layer': 3,\n",
    "#      'proj_num': 1,\n",
    "#      'act_mlp': 'None',\n",
    "#      'item_correction': True,\n",
    "#      'neg_factor': 4,\n",
    "#      'label_smoothing': 0.0,\n",
    "#      'temperature': 1.0,\n",
    "#      'remove_false_neg': False,\n",
    "#      'item_correction_factor': 0.1,\n",
    "#      'transformer_dropout': 0.1,\n",
    "#      'mlm_probability': 0.25,\n",
    "#      'top20': True,\n",
    "#      'loss_types': True,\n",
    "#      'loss_types_type': 'Weighted',\n",
    "#      'multi_task_emb': 16,\n",
    "#      'mt_num_layers': 1,\n",
    "#      'use_tanh': True,\n",
    "#      'seq_len': 50,\n",
    "#      'split': 0\n",
    "# }\n",
    "\n",
    "params = {\n",
    "    'batch_size': 1024,\n",
    "    'lr': 0.0005,\n",
    "    'lr_scheduler': 'cosine',\n",
    "    'num_train_epochs': 1,\n",
    "    'using_test': True,\n",
    "    'using_type': False,\n",
    "    'bl_shuffle': True,\n",
    "    'masking': 'mlm',\n",
    "    'd_model': 256,\n",
    "    'n_head': 32,\n",
    "    'n_layer': 3,\n",
    "    'proj_num': 1,\n",
    "    'act_mlp': 'None',\n",
    "    'item_correction': False,\n",
    "    'neg_factor': 4,\n",
    "    'label_smoothing': 0.0,\n",
    "    'temperature': 1.5734215681668653,\n",
    "    'remove_false_neg': True,\n",
    "    'item_correction_factor': 0.04152252077012748,\n",
    "    'transformer_dropout': 0.05096800263401626,\n",
    "    'mlm_probability': 0.35044384745899415,\n",
    "    'top20': True,\n",
    "    'loss_types': True,\n",
    "    'loss_types_type': 'Simple',\n",
    "    'multi_task_emb': 0,\n",
    "    'mt_num_layers': 1,\n",
    "    'use_tanh': False,\n",
    "    'seq_len': 20,\n",
    "    'split': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['act_mlp'] == 'None':\n",
    "    act_mlp = None\n",
    "else:\n",
    "    act_mlp = torch.nn.ReLU\n",
    "    \n",
    "from transformers4rec.torch.masking import MaskedLanguageModeling\n",
    "\n",
    "masking = 'mlm'\n",
    "if params['masking']=='mlm':\n",
    "    masking = MaskedLanguageModeling(\n",
    "        hidden_size=params['d_model'], \n",
    "        mlm_probability=params['mlm_probability']\n",
    "    )\n",
    "else:\n",
    "    masking = params['masking']\n",
    "    \n",
    "if params['loss_types']:\n",
    "    if params['loss_types']=='Simple':\n",
    "        def custom_loss(x, y, types):\n",
    "            loss = torch.nn.CrossEntropyLoss(\n",
    "                label_smoothing=params['label_smoothing'],\n",
    "                reduce=False\n",
    "            )(x, y)\n",
    "            #loss = loss*(types==1.0)\n",
    "            loss = torch.mean(loss)\n",
    "            return(loss)\n",
    "        loss_fn = custom_loss\n",
    "    else:\n",
    "        def custom_loss(x, y, types):\n",
    "            loss = torch.nn.CrossEntropyLoss(\n",
    "                label_smoothing=params['label_smoothing'],\n",
    "                reduce=False\n",
    "            )(x, y)\n",
    "            loss = loss*(types==1.0)+loss*(types==2.0)*5.0+loss*(types==3.0)*10.0\n",
    "            loss = torch.mean(loss)\n",
    "            return(loss)\n",
    "        loss_fn = custom_loss\n",
    "else:\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(\n",
    "        label_smoothing=params['label_smoothing']\n",
    "    )\n",
    "    \n",
    "if params['mt_num_layers']==1:\n",
    "    mt_tower = torch.nn.Sequential(\n",
    "        torch.nn.Linear(\n",
    "            params['d_model']+params['multi_task_emb'], \n",
    "            params['d_model']\n",
    "        )\n",
    "    )\n",
    "else:\n",
    "    mt_tower = torch.nn.Sequential(\n",
    "            torch.nn.Linear(\n",
    "                params['d_model']+params['multi_task_emb'], \n",
    "                params['d_model']\n",
    "            ),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(\n",
    "                params['d_model'], \n",
    "                params['d_model']\n",
    "            ),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6ac85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = params['seq_len']\n",
    "split = params['split']\n",
    "\n",
    "df_aid = pd.read_parquet('./data/t4r/t4r_map_aid_' + str(seq_len) + '_' + str(split) + '.parquet')\n",
    "df_aid['count'] = df_aid['count']/df_aid['count'].sum()\n",
    "df_aid = pd.concat([\n",
    "    pd.DataFrame({'aid_': [0,1], 'aid':[-1, -1], 'count': 0.00001}),\n",
    "    df_aid]\n",
    ").sort_values(['aid_'])\n",
    "item_probs = torch.Tensor(df_aid['count'].values).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a509fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema().from_proto_text('test.pb')\n",
    "if not params['using_type']:\n",
    "    schema1 = schema.select_by_name(['aid_'])\n",
    "    projection = None\n",
    "else:\n",
    "    schema1 = schema.select_by_name(['aid_', 'type_'])\n",
    "    projection = tr.MLPBlock([params['d_model']]*params['proj_num'])\n",
    "\n",
    "schema2 = schema.select_by_name(['aid_', 'type_'])\n",
    "\n",
    "inputs = CustomTabularSequenceFeatures.from_schema(\n",
    "    schema1,\n",
    "    max_sequence_length=params['seq_len'],\n",
    "    masking=masking,\n",
    "    embedding_dims={\n",
    "        'aid_': params['d_model'],\n",
    "        'type_': 16\n",
    "    },\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8e52672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (heads): ModuleList(\n",
      "    (0): Head(\n",
      "      (body): SequentialBlock(\n",
      "        (0): CustomTabularSequenceFeatures(\n",
      "          (to_merge): ModuleDict(\n",
      "            (categorical_module): SequenceEmbeddingFeatures(\n",
      "              (filter_features): FilterFeatures()\n",
      "              (embedding_tables): ModuleDict(\n",
      "                (aid_): Embedding(1840501, 256, padding_idx=0)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (_aggregation): ConcatFeatures()\n",
      "          (_masking): MaskedLanguageModeling()\n",
      "        )\n",
      "        (1): SequentialBlock(\n",
      "          (0): DenseBlock(\n",
      "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (2): TansformerBlock(\n",
      "          (transformer): XLNetModel(\n",
      "            (word_embedding): Embedding(1, 256)\n",
      "            (layer): ModuleList(\n",
      "              (0): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "              )\n",
      "              (1): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "              )\n",
      "              (2): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.05096800263401626, inplace=False)\n",
      "          )\n",
      "          (masking): MaskedLanguageModeling()\n",
      "        )\n",
      "      )\n",
      "      (prediction_task_dict): ModuleDict(\n",
      "        (next-item): CustomNextItemPredictionTask(\n",
      "          (sequence_summary): SequenceSummary(\n",
      "            (summary): Identity()\n",
      "            (activation): Identity()\n",
      "            (first_dropout): Identity()\n",
      "            (last_dropout): Identity()\n",
      "          )\n",
      "          (metrics): ModuleList(\n",
      "            (0): NDCGAt()\n",
      "            (1): AvgPrecisionAt()\n",
      "            (2): RecallAt()\n",
      "          )\n",
      "          (type_emb): Embedding(4, 0)\n",
      "          (mt_tower): Sequential(\n",
      "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (embeddings): SequenceEmbeddingFeatures(\n",
      "            (filter_features): FilterFeatures()\n",
      "            (embedding_tables): ModuleDict(\n",
      "              (aid_): Embedding(1840501, 256, padding_idx=0)\n",
      "            )\n",
      "          )\n",
      "          (item_embedding_table): Embedding(1840501, 256, padding_idx=0)\n",
      "          (masking): MaskedLanguageModeling()\n",
      "          (pre): Block(\n",
      "            (module): NextItemPredictionTask(\n",
      "              (item_embedding_table): Embedding(1840501, 256, padding_idx=0)\n",
      "              (log_softmax): LogSoftmax(dim=-1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=params['d_model'], \n",
    "    n_head=params['n_head'], \n",
    "    n_layer=params['n_layer'], \n",
    "    dropout=params['transformer_dropout'],\n",
    "    total_seq_length=params['seq_len']\n",
    ")\n",
    "\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, \n",
    "    tr.MLPBlock([params['d_model']], activation=act_mlp), \n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "head = tr.Head(\n",
    "    body,\n",
    "    CustomNextItemPredictionTask(\n",
    "        loss = loss_fn,\n",
    "        weight_tying=True, \n",
    "        item_probs=item_probs, \n",
    "        item_correction=params['item_correction'],\n",
    "        neg_factor=params['neg_factor'],\n",
    "        temperature=params['temperature'],\n",
    "        remove_false_neg=params['remove_false_neg'],\n",
    "        item_correction_factor=params['item_correction_factor'],\n",
    "        loss_types = params['loss_types'],\n",
    "        multi_task = params['multi_task_emb'],\n",
    "        mt_tower = mt_tower,\n",
    "        eval_task = 1,\n",
    "        d_model = params['d_model'],\n",
    "        use_tanh = params['use_tanh']\n",
    "    ),\n",
    "    inputs=inputs,\n",
    ")\n",
    "model = tr.Model(head)\n",
    "\n",
    "print(model)\n",
    "\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "\n",
    "\n",
    "# Set hyperparameters for training \n",
    "\n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last = True,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = params['batch_size'], \n",
    "    per_device_eval_batch_size = 128,\n",
    "    output_dir = \"./tmp-test\", \n",
    "    learning_rate=params['lr'],\n",
    "    lr_scheduler_type=params['lr_scheduler'], \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "    num_train_epochs=1,\n",
    "    max_sequence_length=params['seq_len'], \n",
    "    report_to = [],\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000000,\n",
    "    no_cuda=False,\n",
    "    #resume_from_checkpoint='./tmp_2/checkpoint-50000'\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema2,\n",
    "    compute_metrics=True,\n",
    ")\n",
    "\n",
    "trainer.set_max_seq_len(max_seq_len=params['seq_len'])\n",
    "trainer.set_shuffle(shuffle=params['bl_shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3908e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['using_test']:\n",
    "    trainer.train_dataset_or_path = [\n",
    "        './data/t4r/t4r_train_' + str(seq_len) + '_' + str(split) + '.parquet'\n",
    "    ] + [\n",
    "        './data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet',\n",
    "        './data/t4r/t4r_xgb_sub_x_' + str(seq_len) + '_' + str(split) + '.parquet'\n",
    "    ]\n",
    "else:\n",
    "    trainer.train_dataset_or_path = [\n",
    "        './data/t4r/t4r_train_' + str(seq_len) + '_' + str(split) + '.parquet',\n",
    "        './data/t4r/t4r_xgb_sub_x_' + str(seq_len) + '_' + str(split) + '.parquet'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f92a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = pd.read_parquet('./data/t4r/t4r_map_aid_' + str(seq_len) + '_' + str(split) + '.parquet')\n",
    "map_aid = df_aid.to_records()\n",
    "map_aids = {}\n",
    "\n",
    "for r in map_aid:\n",
    "    map_aids[r[1]] = r[2]\n",
    "\n",
    "map_aids[1] = -1\n",
    "map_aids[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d6846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 14039040\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13710\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13710' max='13710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13710/13710 1:53:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>11.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.737100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.140500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.048900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>6.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>6.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>5.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>5.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.576600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.834300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/t4r/checkpoints/checkpoint_0/\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='163732' max='13936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13936/13936 6:19:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'e': 0, 'recalls1': {'clicks': 0.447318908207546, 'carts': 0.3209616575047485, 'orders': 0.4708972243398599}, 'recalls2': {}, 'recalls3': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14039040\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13710' max='13710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13710/13710 1:53:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.512700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.422800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.363800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.177700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.787000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.262800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/t4r/checkpoints/checkpoint_1/\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'e': 0, 'recalls1': {'clicks': 0.447318908207546, 'carts': 0.3209616575047485, 'orders': 0.4708972243398599}, 'recalls2': {}, 'recalls3': {}}, {'e': 1, 'recalls1': {'clicks': 0.4552056230602548, 'carts': 0.3312011371712864, 'orders': 0.4912973131198111}, 'recalls2': {}, 'recalls3': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 14039040\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 13710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13710' max='13710' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13710/13710 1:52:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.970200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.895600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.816800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.792100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.412400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/t4r/checkpoints/checkpoint_2/\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'e': 0, 'recalls1': {'clicks': 0.447318908207546, 'carts': 0.3209616575047485, 'orders': 0.4708972243398599}, 'recalls2': {}, 'recalls3': {}}, {'e': 1, 'recalls1': {'clicks': 0.4552056230602548, 'carts': 0.3312011371712864, 'orders': 0.4912973131198111}, 'recalls2': {}, 'recalls3': {}}, {'e': 2, 'recalls1': {'clicks': 0.47509416071245686, 'carts': 0.3464527768812795, 'orders': 0.5114272020483722}, 'recalls2': {}, 'recalls3': {}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3454976\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3374' max='3374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3374/3374 16:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.868800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.303700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ./data/t4r/checkpoints/checkpoint_3/\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'e': 0, 'recalls1': {'clicks': 0.447318908207546, 'carts': 0.3209616575047485, 'orders': 0.4708972243398599}, 'recalls2': {}, 'recalls3': {}}, {'e': 1, 'recalls1': {'clicks': 0.4552056230602548, 'carts': 0.3312011371712864, 'orders': 0.4912973131198111}, 'recalls2': {}, 'recalls3': {}}, {'e': 2, 'recalls1': {'clicks': 0.47509416071245686, 'carts': 0.3464527768812795, 'orders': 0.5114272020483722}, 'recalls2': {}, 'recalls3': {}}, {'e': 3, 'recalls1': {'clicks': 0.4689640768107453, 'carts': 0.342050823514473, 'orders': 0.5086737368961114}, 'recalls2': {}, 'recalls3': {}}]\n"
     ]
    }
   ],
   "source": [
    "trainer.reset_lr_scheduler()\n",
    "recall_hist = []\n",
    "for e in range(4):\n",
    "    if e==3:\n",
    "        trainer.train_dataset_or_path = [\n",
    "            './data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet',\n",
    "            './data/t4r/t4r_xgb_sub_x_' + str(seq_len) + '_' + str(split) + '.parquet'\n",
    "        ]\n",
    "    trainer.train()\n",
    "    os.system('mkdir -p ./data/t4r/checkpoints/checkpoint_' + str(e))\n",
    "    trainer.save_model(output_dir = './data/t4r/checkpoints/checkpoint_' + str(e) + '/')\n",
    "    \n",
    "    ### Clicks\n",
    "    eval_paths = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.args.predict_top_k = 20\n",
    "    trainer.test_dataset_or_path = ['./data/t4r/t4r_xgb_test_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.model.wrapper_module.heads[0].prediction_task_dict['next-item'].eval_task = torch.Tensor([1]).long()\n",
    "    prediction = trainer.predict(eval_paths)\n",
    "\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_parquet('./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet', columns=['session'])\n",
    "    df = df.head(prediction[0][0].shape[0])\n",
    "    df['pred'] = prediction[0][0].tolist()\n",
    "    df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x if y in map_aids])\n",
    "    df.columns = ['session', 'labels']\n",
    "\n",
    "    recalls1 = {}\n",
    "    recalls2 = {}\n",
    "    recalls3 = {}\n",
    "\n",
    "    for target_type in ['clicks', 'carts', 'orders']:\n",
    "        test_labels = pd.read_parquet('./data/xgb_train_y.parquet')\n",
    "        test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "        test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "        test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "        recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "        recalls1[target_type] = recall\n",
    "\n",
    "#     ### Carts\n",
    "#     eval_paths = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "#     trainer.args.predict_top_k = 20\n",
    "#     trainer.test_dataset_or_path = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "#     trainer.model.wrapper_module.heads[0].prediction_task_dict['next-item'].eval_task = torch.Tensor([2]).long()\n",
    "#     prediction = trainer.predict(eval_paths)\n",
    "\n",
    "#     import pandas as pd\n",
    "    \n",
    "#     df = pd.read_parquet('./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet', columns=['session'])\n",
    "#     df = df.head(prediction[0][0].shape[0])\n",
    "#     df['pred'] = prediction[0][0].tolist()\n",
    "#     df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x if y in map_aids])\n",
    "#     df.columns = ['session', 'labels']\n",
    "\n",
    "#     recalls2 = {}\n",
    "\n",
    "#     for target_type in ['clicks', 'carts', 'orders']:\n",
    "#         test_labels = pd.read_parquet('./data/xgb_train_y.parquet')\n",
    "#         test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "#         test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "#         test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "#         test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "#         test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "#         recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "#         recalls2[target_type] = recall\n",
    "        \n",
    "#     ### Orders\n",
    "#     eval_paths = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "#     trainer.args.predict_top_k = 20\n",
    "#     trainer.test_dataset_or_path = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "#     trainer.model.wrapper_module.heads[0].prediction_task_dict['next-item'].eval_task = torch.Tensor([3]).long()\n",
    "#     prediction = trainer.predict(eval_paths)\n",
    "\n",
    "#     import pandas as pd\n",
    "    \n",
    "#     df = pd.read_parquet('./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet', columns=['session'])\n",
    "#     df = df.head(prediction[0][0].shape[0])\n",
    "#     df['pred'] = prediction[0][0].tolist()\n",
    "#     df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x if y in map_aids])\n",
    "#     df.columns = ['session', 'labels']\n",
    "\n",
    "#     recalls3 = {}\n",
    "\n",
    "#     for target_type in ['clicks', 'carts', 'orders']:\n",
    "#         test_labels = pd.read_parquet('./data/xgb_train_y.parquet')\n",
    "#         test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "#         test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "#         test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "#         test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "#         test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "#         recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "#         recalls3[target_type] = recall\n",
    "    recall_hist.append({\n",
    "        'e': e,\n",
    "        'recalls1': recalls1,\n",
    "        'recalls2': recalls2,\n",
    "        'recalls3': recalls3\n",
    "    })\n",
    "    print(recall_hist)\n",
    "    \n",
    "    os.system('mkdir -p ./data/t4r/train_pred/pred_' + str(e))\n",
    "    \n",
    "    topk = 50\n",
    "    eval_paths = ['./data/t4r/t4r_xgb_train_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.args.predict_top_k = topk\n",
    "    trainer.test_dataset_or_path = ['./data/t4r/t4r_xgb_test_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.model.wrapper_module.heads[0].prediction_task_dict['next-item'].eval_task = torch.Tensor([1]).long()\n",
    "    prediction = trainer.predict(eval_paths)\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(eval_paths[0], columns=['session'])\n",
    "    assert df.shape[0]==prediction[0][0].shape[0]\n",
    "    df['pred'] = prediction[0][0].tolist()\n",
    "    df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x if y in map_aids])\n",
    "    df = cudf.from_pandas(df)\n",
    "    for i in range(topk):\n",
    "        df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "    df.drop(['pred'], inplace=True, axis=1)\n",
    "    df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "    df['order'] = df['variable'].cat.codes.astype('int')\n",
    "    df[['session', 'value', 'order']].to_parquet('./data/t4r/train_pred/pred_' + str(e) + '/rec.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(eval_paths[0], columns=['session'])\n",
    "    assert df.shape[0]==prediction[0][0].shape[0]\n",
    "    pred2 = torch.nn.Softmax(dim=1)(torch.Tensor(prediction[0][1]))\n",
    "    pred2 = pred2.numpy()\n",
    "    df['pred'] = pred2.tolist()\n",
    "    df = cudf.from_pandas(df)\n",
    "    for i in range(topk):\n",
    "        df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "    df.drop(['pred'], inplace=True, axis=1)\n",
    "    df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "    df['order'] = df['variable'].cat.codes.astype('int')\n",
    "    df[['session', 'value', 'order']].to_parquet('./data/t4r/train_pred/pred_' + str(e) + '/score.parquet')\n",
    "    del df, pred2\n",
    "    gc.collect()\n",
    "    \n",
    "    os.system('mkdir -p ./data/t4r/sub_pred/pred_' + str(e))\n",
    "    \n",
    "    eval_paths = ['./data/t4r/t4r_xgb_sub_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.args.predict_top_k = topk\n",
    "    trainer.test_dataset_or_path = ['./data/t4r/t4r_xgb_sub_x_' + str(seq_len) + '_' + str(split) + '.parquet']\n",
    "    trainer.model.wrapper_module.heads[0].prediction_task_dict['next-item'].eval_task = torch.Tensor([1]).long()\n",
    "    prediction = trainer.predict(eval_paths)\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(eval_paths[0], columns=['session'])\n",
    "    assert df.shape[0]==prediction[0][0].shape[0]\n",
    "    df['pred'] = prediction[0][0].tolist()\n",
    "    df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x if y in map_aids])\n",
    "    df = cudf.from_pandas(df)\n",
    "    for i in range(topk):\n",
    "        df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "    df.drop(['pred'], inplace=True, axis=1)\n",
    "    df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "    df['order'] = df['variable'].cat.codes.astype('int')\n",
    "    df[['session', 'value', 'order']].to_parquet('./data/t4r/sub_pred/pred_' + str(e) + '/rec.parquet')\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.read_parquet(eval_paths[0], columns=['session'])\n",
    "    assert df.shape[0]==prediction[0][0].shape[0]\n",
    "    pred2 = torch.nn.Softmax(dim=1)(torch.Tensor(prediction[0][1]))\n",
    "    pred2 = pred2.numpy()\n",
    "    df['pred'] = pred2.tolist()\n",
    "    df = cudf.from_pandas(df)\n",
    "    for i in range(topk):\n",
    "        df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "    df.drop(['pred'], inplace=True, axis=1)\n",
    "    df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "    df['order'] = df['variable'].cat.codes.astype('int')\n",
    "    df[['session', 'value', 'order']].to_parquet('./data/t4r/sub_pred/pred_' + str(e) + '/score.parquet')\n",
    "    del df, pred2\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
