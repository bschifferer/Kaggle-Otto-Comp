{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4221193a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 21 13:06:05 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    44W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0   148W / 163W |  20540MiB / 32510MiB |     72%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5b254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (AvgPrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (NDCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (DCGAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (AvgPrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (PrecisionAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.8/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (RecallAt). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers4rec import torch as tr\n",
    "\n",
    "from merlin_standard_lib import Schema\n",
    "import torch \n",
    "\n",
    "from custom_t4r import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3439a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTabularSequenceFeatures(tr.TabularSequenceFeatures):\n",
    "    def forward(self, inputs, training=False, testing=False, **kwargs):\n",
    "        self.to_merge.categorical_module.type_seq = inputs['type_']\n",
    "        outputs = super(CustomTabularSequenceFeatures, self).forward(inputs, training=training, testing=testing, **kwargs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1192c09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Param\n",
    "batch_size = 1024\n",
    "lr = 0.0005\n",
    "lr_scheduler = 'constant' # cosine\n",
    "num_train_epochs = 1\n",
    "using_test = True\n",
    "using_type = True\n",
    "bl_shuffle = True\n",
    "\n",
    "# Transformer Architecture\n",
    "d_model = 64\n",
    "n_head = 8\n",
    "n_layer = 3\n",
    "proj_num = 2\n",
    "act_mlp = torch.nn.ReLU\n",
    "act_mlp = None\n",
    "\n",
    "# Next Item Prediction\n",
    "item_correction = True\n",
    "neg_factor=1\n",
    "label_smoothing=0.0\n",
    "temperature=1.0\n",
    "remove_false_neg = False\n",
    "item_correction_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9682f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': batch_size,\n",
    "    'lr': lr,\n",
    "    'lr_scheduler': lr_scheduler,\n",
    "    'num_train_epochs': num_train_epochs,\n",
    "    'using_test': using_test,\n",
    "    'using_type':using_type,\n",
    "    'bl_shuffle': bl_shuffle,\n",
    "    'd_model': d_model,\n",
    "    'n_head': n_head,\n",
    "    'n_layer': n_layer,\n",
    "    'proj_num': proj_num,\n",
    "    'act_mlp': act_mlp,\n",
    "    'item_correction': item_correction,\n",
    "    'neg_factor': neg_factor,\n",
    "    'label_smoothing': label_smoothing,\n",
    "    'temperature': temperature,\n",
    "    'remove_false_neg': remove_false_neg,\n",
    "    'item_correction_factor': item_correction_factor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47122070",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 1024,\n",
    "    'lr': 0.0005,\n",
    "    'lr_scheduler': 'constant',\n",
    "    'num_train_epochs': 1,\n",
    "    'using_test': False,\n",
    "    'using_type': True,\n",
    "    'bl_shuffle': False,\n",
    "    'masking': 'mlm',\n",
    "    'd_model': 256,\n",
    "    'n_head': 4,\n",
    "    'n_layer': 4,\n",
    "    'proj_num': 1,\n",
    "    'act_mlp': 'ReLu',\n",
    "    'item_correction': False,\n",
    "    'neg_factor': 8,\n",
    "    'label_smoothing': 0.0,\n",
    "    'temperature': 1.962964566678596,\n",
    "    'remove_false_neg': False, # Should be True\n",
    "    'item_correction_factor': 0.0978173779982345,\n",
    "    'top20': True,\n",
    "    'loss_types': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a0960e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if act_mlp == 'None':\n",
    "    act_mlp = None\n",
    "else:\n",
    "    act_mlp = torch.nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6ac85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = pd.read_parquet('./data/t4r_map_aid.parquet')\n",
    "df_aid['count'] = df_aid['count']/df_aid['count'].sum()\n",
    "df_aid = pd.concat([\n",
    "    pd.DataFrame({'aid_': [0,1], 'aid':[-1, -1], 'count': 0.00001}),\n",
    "    df_aid]\n",
    ").sort_values(['aid_'])\n",
    "item_probs = torch.Tensor(df_aid['count'].values).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a509fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema().from_proto_text('test.pb')\n",
    "if not using_type:\n",
    "    schema1 = schema.select_by_name(['aid_'])\n",
    "    projection = None\n",
    "else:\n",
    "    schema1 = schema.select_by_name(['aid_'])\n",
    "    projection = tr.MLPBlock([params['d_model']]*proj_num)\n",
    "    prediction = None\n",
    "\n",
    "schema2 = schema.select_by_name(['aid_', 'type_'])\n",
    "\n",
    "inputs = CustomTabularSequenceFeatures.from_schema(\n",
    "    schema1,\n",
    "    max_sequence_length=20,\n",
    "    masking=params['masking'],\n",
    "    embedding_dims={\n",
    "        'aid_': params['d_model'],\n",
    "        'type_': 16\n",
    "    },\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6e5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x, y, types):\n",
    "    loss = torch.nn.CrossEntropyLoss(\n",
    "        label_smoothing=params['label_smoothing'],\n",
    "        reduce=False\n",
    "    )(x, y)\n",
    "    #loss = loss*(types==1.0)\n",
    "    loss = torch.mean(loss)\n",
    "    return(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e52672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (heads): ModuleList(\n",
      "    (0): Head(\n",
      "      (body): SequentialBlock(\n",
      "        (0): CustomTabularSequenceFeatures(\n",
      "          (to_merge): ModuleDict(\n",
      "            (categorical_module): SequenceEmbeddingFeatures(\n",
      "              (filter_features): FilterFeatures()\n",
      "              (embedding_tables): ModuleDict(\n",
      "                (aid_): Embedding(1825326, 256, padding_idx=0)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (_aggregation): ConcatFeatures()\n",
      "          (projection_module): SequentialBlock(\n",
      "            (0): DenseBlock(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "            )\n",
      "            (1): DenseBlock(\n",
      "              (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (1): ReLU(inplace=True)\n",
      "            )\n",
      "          )\n",
      "          (_masking): MaskedLanguageModeling()\n",
      "        )\n",
      "        (1): SequentialBlock(\n",
      "          (0): DenseBlock(\n",
      "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): TansformerBlock(\n",
      "          (transformer): XLNetModel(\n",
      "            (word_embedding): Embedding(1, 256)\n",
      "            (layer): ModuleList(\n",
      "              (0): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (1): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (2): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (3): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (masking): MaskedLanguageModeling()\n",
      "        )\n",
      "      )\n",
      "      (prediction_task_dict): ModuleDict(\n",
      "        (next-item): CustomNextItemPredictionTask(\n",
      "          (sequence_summary): SequenceSummary(\n",
      "            (summary): Identity()\n",
      "            (activation): Identity()\n",
      "            (first_dropout): Identity()\n",
      "            (last_dropout): Identity()\n",
      "          )\n",
      "          (metrics): ModuleList(\n",
      "            (0): NDCGAt()\n",
      "            (1): AvgPrecisionAt()\n",
      "            (2): RecallAt()\n",
      "          )\n",
      "          (type_emb): Embedding(4, 1)\n",
      "          (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      "          (embeddings): SequenceEmbeddingFeatures(\n",
      "            (filter_features): FilterFeatures()\n",
      "            (embedding_tables): ModuleDict(\n",
      "              (aid_): Embedding(1825326, 256, padding_idx=0)\n",
      "            )\n",
      "          )\n",
      "          (item_embedding_table): Embedding(1825326, 256, padding_idx=0)\n",
      "          (masking): MaskedLanguageModeling()\n",
      "          (pre): Block(\n",
      "            (module): NextItemPredictionTask(\n",
      "              (item_embedding_table): Embedding(1825326, 256, padding_idx=0)\n",
      "              (log_softmax): LogSoftmax(dim=-1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=params['d_model'], n_head=params['n_head'], n_layer=params['n_layer'], total_seq_length=20\n",
    ")\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, \n",
    "    tr.MLPBlock([params['d_model']], activation=act_mlp), \n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "head = tr.Head(\n",
    "    body,\n",
    "    CustomNextItemPredictionTask(\n",
    "        loss = custom_loss,\n",
    "        weight_tying=True, \n",
    "        item_probs=item_probs, \n",
    "        item_correction=params['item_correction'],\n",
    "        neg_factor=params['neg_factor'],\n",
    "        temperature=params['temperature'],\n",
    "        remove_false_neg=params['remove_false_neg'],\n",
    "        item_correction_factor=params['item_correction_factor'],\n",
    "        loss_types=params['loss_types']\n",
    "    ),\n",
    "    inputs=inputs,\n",
    ")\n",
    "model = tr.Model(head)\n",
    "print(model)\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "\n",
    "\n",
    "# Set hyperparameters for training \n",
    "\n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last = True,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = params['batch_size'], \n",
    "    per_device_eval_batch_size = 128,\n",
    "    output_dir = \"./tmp-test\", \n",
    "    learning_rate=params['lr'],\n",
    "    lr_scheduler_type=params['lr_scheduler'], \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "    num_train_epochs=1,\n",
    "    max_sequence_length=20, \n",
    "    report_to = [],\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000000,\n",
    "    no_cuda=False,\n",
    "    #resume_from_checkpoint='./tmp_2/checkpoint-50000'\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema2,\n",
    "    compute_metrics=True,\n",
    ")\n",
    "\n",
    "trainer.set_shuffle(shuffle=params['bl_shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3908e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['using_test']:\n",
    "    trainer.train_dataset_or_path = ['./data/t4r_train.parquet'] + ['./data/t4r_xgb_train_x.parquet']\n",
    "else:\n",
    "    trainer.train_dataset_or_path = ['./data/t4r_train.parquet']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2d6846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n",
      "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10336' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10336/10336 41:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.237500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>6.731500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>6.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.849700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>5.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.869800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outout = {}\n",
    "for epoch in range(1):\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5ae517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = trainer.get_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ae85dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0328c5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [3, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9344e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [3, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.to_merge.categorical_module.type_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(x, y, types):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52afc41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b43f5b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (heads): ModuleList(\n",
      "    (0): Head(\n",
      "      (body): SequentialBlock(\n",
      "        (0): TabularSequenceFeatures(\n",
      "          (to_merge): ModuleDict(\n",
      "            (categorical_module): SequenceEmbeddingFeatures(\n",
      "              (filter_features): FilterFeatures()\n",
      "              (embedding_tables): ModuleDict(\n",
      "                (aid_): Embedding(1825326, 256, padding_idx=0)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (_aggregation): ConcatFeatures()\n",
      "          (_masking): MaskedLanguageModeling()\n",
      "        )\n",
      "        (1): SequentialBlock(\n",
      "          (0): DenseBlock(\n",
      "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (1): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): TansformerBlock(\n",
      "          (transformer): XLNetModel(\n",
      "            (word_embedding): Embedding(1, 256)\n",
      "            (layer): ModuleList(\n",
      "              (0): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (1): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (2): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "              (3): XLNetLayer(\n",
      "                (rel_attn): XLNetRelativeAttention(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                )\n",
      "                (ff): XLNetFeedForward(\n",
      "                  (layer_norm): LayerNorm((256,), eps=0.03, elementwise_affine=True)\n",
      "                  (layer_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "                  (layer_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "                  (dropout): Dropout(p=0.3, inplace=False)\n",
      "                  (activation_function): GELUActivation()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.3, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (dropout): Dropout(p=0.3, inplace=False)\n",
      "          )\n",
      "          (masking): MaskedLanguageModeling()\n",
      "        )\n",
      "      )\n",
      "      (prediction_task_dict): ModuleDict(\n",
      "        (next-item): CustomNextItemPredictionTask(\n",
      "          (sequence_summary): SequenceSummary(\n",
      "            (summary): Identity()\n",
      "            (activation): Identity()\n",
      "            (first_dropout): Identity()\n",
      "            (last_dropout): Identity()\n",
      "          )\n",
      "          (metrics): ModuleList(\n",
      "            (0): NDCGAt()\n",
      "            (1): AvgPrecisionAt()\n",
      "            (2): RecallAt()\n",
      "          )\n",
      "          (loss): CrossEntropyLoss()\n",
      "          (embeddings): SequenceEmbeddingFeatures(\n",
      "            (filter_features): FilterFeatures()\n",
      "            (embedding_tables): ModuleDict(\n",
      "              (aid_): Embedding(1825326, 256, padding_idx=0)\n",
      "            )\n",
      "          )\n",
      "          (item_embedding_table): Embedding(1825326, 256, padding_idx=0)\n",
      "          (masking): MaskedLanguageModeling()\n",
      "          (pre): Block(\n",
      "            (module): NextItemPredictionTask(\n",
      "              (item_embedding_table): Embedding(1825326, 256, padding_idx=0)\n",
      "              (log_softmax): LogSoftmax(dim=-1)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "schema = Schema().from_proto_text('test.pb')\n",
    "if using_type:\n",
    "    schema1 = schema.select_by_name(['aid_'])\n",
    "    projection = None\n",
    "else:\n",
    "    schema1 = schema.select_by_name(['aid_', 'type_'])\n",
    "    projection = tr.MLPBlock([params['d_model']]*proj_num)\n",
    "\n",
    "schema2 = schema.select_by_name(['aid_', 'type_'])\n",
    "\n",
    "df_aid = pd.read_parquet('./data/t4r_map_aid.parquet')\n",
    "df_aid['count'] = df_aid['count']/df_aid['count'].sum()\n",
    "df_aid = pd.concat([\n",
    "    pd.DataFrame({'aid_': [0,1], 'aid':[-1, -1], 'count': 0.00001}),\n",
    "    df_aid]\n",
    ").sort_values(['aid_'])\n",
    "item_probs = torch.Tensor(df_aid['count'].values).cuda()\n",
    "\n",
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema1,\n",
    "    max_sequence_length=20,\n",
    "    masking=params['masking'],\n",
    "    embedding_dims={\n",
    "        'aid_': params['d_model'],\n",
    "        'type_': 16\n",
    "    },\n",
    "    projection=projection\n",
    ")\n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=params['d_model'], n_head=params['n_head'], n_layer=params['n_layer'], total_seq_length=20\n",
    ")\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, \n",
    "    tr.MLPBlock([params['d_model']], activation=act_mlp), \n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "head = tr.Head(\n",
    "    body,\n",
    "    CustomNextItemPredictionTask(\n",
    "        loss = torch.nn.CrossEntropyLoss(label_smoothing=params['label_smoothing']),\n",
    "        weight_tying=True, \n",
    "        item_probs=item_probs, \n",
    "        item_correction=params['item_correction'],\n",
    "        neg_factor=params['neg_factor'],\n",
    "        temperature=params['temperature'],\n",
    "        remove_false_neg=params['remove_false_neg'],\n",
    "        item_correction_factor=params['item_correction_factor']\n",
    "    ),\n",
    "    inputs=inputs,\n",
    ")\n",
    "model = tr.Model(head)\n",
    "print(model)\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "\n",
    "\n",
    "# Set hyperparameters for training \n",
    "\n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last = True,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = params['batch_size'], \n",
    "    per_device_eval_batch_size = 128,\n",
    "    output_dir = \"./tmp-test\", \n",
    "    learning_rate=params['lr'],\n",
    "    lr_scheduler_type=params['lr_scheduler'], \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "    num_train_epochs=1,\n",
    "    max_sequence_length=20, \n",
    "    report_to = [],\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000000,\n",
    "    no_cuda=False,\n",
    "    #resume_from_checkpoint='./tmp_2/checkpoint-50000'\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema2,\n",
    "    compute_metrics=True,\n",
    ")\n",
    "\n",
    "trainer.set_shuffle(shuffle=params['bl_shuffle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c922f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates\t\t test\t\t\t\t xgb_test_x.parquet\r\n",
      "t4r_map_aid.parquet\t top_15_buy2buy_v3.parquet\t xgb_test_y.parquet\r\n",
      "t4r_train.parquet\t top_15_carts_orders_v3.parquet  xgb_train_x.parquet\r\n",
      "t4r_xgb_test_x.parquet\t top_20_clicks_v3.parquet\t xgb_train_y.parquet\r\n",
      "t4r_xgb_train_x.parquet  train\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ff8cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10336' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10336/10336 40:53, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.134800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.667700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.655300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.344200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.100300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.695300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.368000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outout = {}\n",
    "for epoch in range(1):\n",
    "    if params['using_test']:\n",
    "        trainer.train_dataset_or_path = ['./data/t4r_train.parquet'] + ['./data/t4r_xgb_train_x.parquet']\n",
    "    else:\n",
    "        trainer.train_dataset_or_path = ['./data/t4r_train.parquet']\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0646c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13936' max='13936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13936/13936 08:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_paths = ['./data/t4r_xgb_test_x.parquet']\n",
    "trainer.args.predict_top_k = 20\n",
    "trainer.test_dataset_or_path = ['./data/t4r_xgb_test_x.parquet']\n",
    "prediction = trainer.predict(eval_paths)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/t4r_xgb_test_x.parquet', columns=['session'])\n",
    "df = df.head(prediction[0][0].shape[0])\n",
    "df['pred'] = prediction[0][0].tolist()\n",
    "df_aid = pd.read_parquet('./data/t4r_map_aid.parquet')\n",
    "map_aid = df_aid.to_records()\n",
    "map_aids = {}\n",
    "\n",
    "for r in map_aid:\n",
    "    map_aids[r[1]] = r[2]\n",
    "\n",
    "map_aids[1] = -1\n",
    "map_aids[0] = -1\n",
    "\n",
    "df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "df.columns = ['session', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bddf3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = {}\n",
    "\n",
    "for target_type in ['clicks']:\n",
    "    test_labels = pd.read_parquet('./data/xgb_test_y.parquet')\n",
    "    test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "    test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "    test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "    test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "    test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "    recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "    recalls[target_type] = recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c03a174d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clicks': 0.3197804815458813}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c31f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd1968e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cb0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "254e9f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clicks': 0.31261183922079927}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ce032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clicks': 0.31261183922079927}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56040baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data/candidates/test/t4r\n",
    "!mkdir -p ./data/candidates/train/t4r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8b6d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 40\n",
    "eval_paths = ['./data/t4r_xgb_test_x.parquet']\n",
    "trainer.args.predict_top_k = topk\n",
    "trainer.test_dataset_or_path = ['./data/t4r_xgb_test_x.parquet']\n",
    "prediction = trainer.predict(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1c84a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = pd.read_parquet('./data/t4r_map_aid.parquet')\n",
    "map_aid = df_aid.to_records()\n",
    "map_aids = {}\n",
    "\n",
    "for r in map_aid:\n",
    "    map_aids[r[1]] = r[2]\n",
    "\n",
    "map_aids[1] = -1\n",
    "map_aids[0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af5a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 6.8 s, total: 1min 46s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/t4r_xgb_test_x.parquet', columns=['session'])\n",
    "df = df.head(prediction[0][0].shape[0])\n",
    "df['pred'] = prediction[0][0].tolist()\n",
    "df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "df = cudf.from_pandas(df)\n",
    "for i in range(topk):\n",
    "    df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "df.drop(['pred'], inplace=True, axis=1)\n",
    "df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "df['t4r_score'] = 1/(1+df['variable'].cat.codes)\n",
    "df[['session', 'value', 't4r_score']].rename(\n",
    "    columns={'value': 'cand'}\n",
    ").to_parquet('./data/candidates/test/t4r/cand.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c9f2b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a2dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 40\n",
    "eval_paths = ['./data/t4r_xgb_train_x.parquet']\n",
    "trainer.args.predict_top_k = topk\n",
    "trainer.test_dataset_or_path = ['./data/t4r_xgb_train_x.parquet']\n",
    "prediction = trainer.predict(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5b85f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.4 s, sys: 2.59 s, total: 51 s\n",
      "Wall time: 51.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('./data/t4r_xgb_train_x.parquet', columns=['session'])\n",
    "df = df.head(prediction[0][0].shape[0])\n",
    "df['pred'] = prediction[0][0].tolist()\n",
    "df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "df = cudf.from_pandas(df)\n",
    "for i in range(topk):\n",
    "    df['rec_' + str(i)] = df.pred.list.get(i, default=-1)\n",
    "df.drop(['pred'], inplace=True, axis=1)\n",
    "df = cudf.melt(df, id_vars=['session'], value_vars=['rec_' + str(i) for i in range(topk)])\n",
    "df['t4r_score'] = 1/(1+df['variable'].cat.codes)\n",
    "df[['session', 'value', 't4r_score']].rename(\n",
    "    columns={'value': 'cand'}\n",
    ").to_parquet('./data/candidates/train/t4r/cand.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25653d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40670810927130596"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c79eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2b99688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['t4r_score'] = 1/(1+df['variable'].cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "155400da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1.000\n",
       "1           1.000\n",
       "2           1.000\n",
       "3           1.000\n",
       "4           1.000\n",
       "            ...  \n",
       "71349475    0.025\n",
       "71349476    0.025\n",
       "71349477    0.025\n",
       "71349478    0.025\n",
       "71349479    0.025\n",
       "Name: t4r_score, Length: 71349480, dtype: float32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['t4r_score'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "310b852c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "791cfd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28238109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29aed540",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['variable'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b636b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recalls = {}\n",
    "\n",
    "for target_type in ['clicks', 'carts', \"orders\"]:\n",
    "    test_labels = pd.read_parquet(path + '/test_labels.parquet')\n",
    "    test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "    test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "    test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "    test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "    test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "    recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "    recalls[target_type] = recall\n",
    "print(epoch, recalls)\n",
    "outout[epoch] = recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fcc88e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10336' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10336/10336 1:02:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.344700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.501400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.498600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.275200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.002100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'clicks': 0.4395167740131393, 'carts': 0.2949520388133773, 'orders': 0.40411926106773977}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10336' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10336/10336 1:03:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.541200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.447600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.363300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.227800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.954600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'clicks': 0.4388637192704659, 'carts': 0.2944088490549733, 'orders': 0.403273278199697}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10336' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10336/10336 1:03:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.483900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.462900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.343200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.289300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.927900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 {'clicks': 0.43934416042476754, 'carts': 0.2944776295763296, 'orders': 0.4030834949707444}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 10584064\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 10336\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3113' max='10336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3113/10336 18:24 < 42:45, 2.82 it/s, Epoch 0.30/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.447000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    if params['using_test']:\n",
    "        trainer.train_dataset_or_path = [path + 'data/train.parquet'] + [path + 'data/test.parquet']\n",
    "    else:\n",
    "        trainer.train_dataset_or_path = [path + 'data/train.parquet']\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "\n",
    "    eval_paths = [path + 'data/test.parquet']\n",
    "    trainer.args.predict_top_k = 20\n",
    "    trainer.test_dataset_or_path = [path + 'data/test.parquet']\n",
    "    prediction = trainer.predict(eval_paths)\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_parquet(path + 'data/test.parquet', columns=['session'])\n",
    "    df = df.head(prediction[0][0].shape[0])\n",
    "    df['pred'] = prediction[0][0].tolist()\n",
    "    df_aid = pd.read_parquet(path + '/data/map_aid.parquet')\n",
    "    map_aid = df_aid.to_records()\n",
    "    map_aids = {}\n",
    "\n",
    "    for r in map_aid:\n",
    "        map_aids[r[1]] = r[2]\n",
    "\n",
    "    map_aids[1] = -1\n",
    "    map_aids[0] = -1\n",
    "\n",
    "    df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "    df.columns = ['session', 'labels']\n",
    "\n",
    "    recalls = {}\n",
    "\n",
    "    for target_type in ['clicks', 'carts', \"orders\"]:\n",
    "        test_labels = pd.read_parquet(path + '/test_labels.parquet')\n",
    "        test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "        test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "        test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "        test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "        recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "        recalls[target_type] = recall\n",
    "    print(epoch, recalls)\n",
    "    outout[epoch+13] = recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9063a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'clicks': 0.4093698108039996,\n",
       "  'carts': 0.27327735657056795,\n",
       "  'orders': 0.3745581106597058},\n",
       " 1: {'clicks': 0.42505175530758016,\n",
       "  'carts': 0.28394186458702586,\n",
       "  'orders': 0.38732183697298966},\n",
       " 2: {'clicks': 0.4333475643647302,\n",
       "  'carts': 0.29088693364090573,\n",
       "  'orders': 0.398335697582033},\n",
       " 3: {'clicks': 0.4368677308102597,\n",
       "  'carts': 0.29359759162359067,\n",
       "  'orders': 0.40266854519896683},\n",
       " 4: {'clicks': 0.43769282376267704,\n",
       "  'carts': 0.2933806684408514,\n",
       "  'orders': 0.4010473460906263},\n",
       " 5: {'clicks': 0.4364407998683534,\n",
       "  'carts': 0.29198036757016055,\n",
       "  'orders': 0.39820703098613297},\n",
       " 6: {'clicks': 0.4379183721848162,\n",
       "  'carts': 0.29383567804367033,\n",
       "  'orders': 0.40181291233623156},\n",
       " 7: {'clicks': 0.4384862708905595,\n",
       "  'carts': 0.2939256218023671,\n",
       "  'orders': 0.4013593625856839},\n",
       " 8: {'clicks': 0.43876072649607073,\n",
       "  'carts': 0.29437357699273925,\n",
       "  'orders': 0.40322824489113196},\n",
       " 9: {'clicks': 0.4382302274011413,\n",
       "  'carts': 0.2940085111486171,\n",
       "  'orders': 0.40380724457268213},\n",
       " 11: {'clicks': 0.43938501230734883,\n",
       "  'carts': 0.2944441211172073,\n",
       "  'orders': 0.4026331618850943},\n",
       " 13: {'clicks': 0.4395167740131393,\n",
       "  'carts': 0.2949520388133773,\n",
       "  'orders': 0.40411926106773977},\n",
       " 14: {'clicks': 0.4388637192704659,\n",
       "  'carts': 0.2944088490549733,\n",
       "  'orders': 0.403273278199697},\n",
       " 15: {'clicks': 0.43934416042476754,\n",
       "  'carts': 0.2944776295763296,\n",
       "  'orders': 0.4030834949707444}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770c11ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_paths = [path + 'data/test.parquet']\n",
    "trainer.args.predict_top_k = 20\n",
    "trainer.test_dataset_or_path = [path + 'data/test.parquet']\n",
    "prediction = trainer.predict(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d655bb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=(array([[ 64741,  36670,  24906, ...,   6683, 217820,  12693],\n",
       "       [135681,  57674,  61132, ...,  48042,  23134,  12618],\n",
       "       [  5233,    465,   5202, ...,    454,  76046,   2601],\n",
       "       ...,\n",
       "       [167262,  18758,  19317, ...,  78228,   2796,   9786],\n",
       "       [ 15513,  10764,  13103, ...,  10983, 117849,  14583],\n",
       "       [120020, 117659,  56312, ..., 238944, 140828, 406793]]), array([[24.68053 , 23.489492, 22.749798, ..., 20.471788, 20.45895 ,\n",
       "        20.447681],\n",
       "       [34.522373, 23.81918 , 23.412258, ..., 20.423279, 20.341911,\n",
       "        20.282814],\n",
       "       [28.116419, 22.63007 , 22.254469, ..., 18.253366, 18.046333,\n",
       "        17.892616],\n",
       "       ...,\n",
       "       [32.94166 , 21.69962 , 20.959791, ..., 19.10243 , 19.097216,\n",
       "        19.021849],\n",
       "       [27.69482 , 27.61845 , 26.228548, ..., 19.584465, 18.8672  ,\n",
       "        18.861032],\n",
       "       [38.39622 , 30.486069, 26.92591 , ..., 19.255077, 19.011198,\n",
       "        18.970572]], dtype=float32)), label_ids=None, metrics={'test_runtime': 486.1973, 'test_samples_per_second': 3668.897, 'test_steps_per_second': 28.663})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5082901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(path + 'data/test.parquet', columns=['session'])\n",
    "df = df.head(prediction[0][0].shape[0])\n",
    "df['pred'] = prediction[0][0].tolist()\n",
    "df_aid = pd.read_parquet(path + '/data/map_aid.parquet')\n",
    "map_aid = df_aid.to_records()\n",
    "\n",
    "map_aids = {}\n",
    "\n",
    "for r in map_aid:\n",
    "    map_aids[r[1]] = r[2]\n",
    "\n",
    "map_aids[1] = -1\n",
    "map_aids[0] = -1\n",
    "\n",
    "df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "df['score'] = prediction[0][1].tolist()\n",
    "df.to_parquet('./data/pred_transformer.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1adae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e418ce15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d709ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema().from_proto_text('test.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb021e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_type:\n",
    "    schema1 = schema.select_by_name(['aid_'])\n",
    "    projection = None\n",
    "else:\n",
    "    schema1 = schema.select_by_name(['aid_', 'type_'])\n",
    "    projection = tr.MLPBlock([d_model]*proj_num)\n",
    "\n",
    "schema2 = schema.select_by_name(['aid_', 'type_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fab3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = pd.read_parquet(path + '/data/map_aid.parquet')\n",
    "df_aid['count'] = df_aid['count']/df_aid['count'].sum()\n",
    "df_aid = pd.concat([\n",
    "    pd.DataFrame({'aid_': [0,1], 'aid':[-1, -1], 'count': 0.00001}),\n",
    "    df_aid]\n",
    ").sort_values(['aid_'])\n",
    "item_probs = torch.Tensor(df_aid['count'].values).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df232a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "    schema1,\n",
    "    max_sequence_length=20,\n",
    "    masking=\"mlm\",\n",
    "    embedding_dims={\n",
    "        'aid_': d_model,\n",
    "        'type_': 16\n",
    "    },\n",
    "    projection=projection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864f7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=d_model, n_head=n_head, n_layer=n_layer, total_seq_length=20\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, \n",
    "    tr.MLPBlock([d_model], activation=act_mlp), \n",
    "    tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Define the evaluation top-N metrics and the cut-offs\n",
    "\n",
    "\n",
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    CustomNextItemPredictionTask(\n",
    "        loss = torch.nn.CrossEntropyLoss(label_smoothing=label_smoothing),\n",
    "        weight_tying=True, \n",
    "        item_probs=item_probs, \n",
    "        item_correction=item_correction,\n",
    "        neg_factor=neg_factor,\n",
    "        temperature=temperature,\n",
    "        remove_false_neg=remove_false_neg,\n",
    "        item_correction_factor=item_correction_factor\n",
    "    ),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bafa7023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (heads): ModuleList(\n",
       "    (0): Head(\n",
       "      (body): SequentialBlock(\n",
       "        (0): TabularSequenceFeatures(\n",
       "          (to_merge): ModuleDict(\n",
       "            (categorical_module): SequenceEmbeddingFeatures(\n",
       "              (filter_features): FilterFeatures()\n",
       "              (embedding_tables): ModuleDict(\n",
       "                (aid_): Embedding(1825326, 64, padding_idx=0)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (_aggregation): ConcatFeatures()\n",
       "          (_masking): CausalLanguageModeling()\n",
       "        )\n",
       "        (1): SequentialBlock(\n",
       "          (0): DenseBlock(\n",
       "            (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (2): TansformerBlock(\n",
       "          (transformer): XLNetModel(\n",
       "            (word_embedding): Embedding(1, 64)\n",
       "            (layer): ModuleList(\n",
       "              (0): XLNetLayer(\n",
       "                (rel_attn): XLNetRelativeAttention(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (ff): XLNetFeedForward(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (layer_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (layer_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (1): XLNetLayer(\n",
       "                (rel_attn): XLNetRelativeAttention(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (ff): XLNetFeedForward(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (layer_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (layer_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "              (2): XLNetLayer(\n",
       "                (rel_attn): XLNetRelativeAttention(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (ff): XLNetFeedForward(\n",
       "                  (layer_norm): LayerNorm((64,), eps=0.03, elementwise_affine=True)\n",
       "                  (layer_1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (layer_2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.3, inplace=False)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.3, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "          (masking): CausalLanguageModeling()\n",
       "        )\n",
       "      )\n",
       "      (prediction_task_dict): ModuleDict(\n",
       "        (next-item): CustomNextItemPredictionTask(\n",
       "          (sequence_summary): SequenceSummary(\n",
       "            (summary): Identity()\n",
       "            (activation): Identity()\n",
       "            (first_dropout): Identity()\n",
       "            (last_dropout): Identity()\n",
       "          )\n",
       "          (metrics): ModuleList(\n",
       "            (0): NDCGAt()\n",
       "            (1): AvgPrecisionAt()\n",
       "            (2): RecallAt()\n",
       "          )\n",
       "          (loss): CrossEntropyLoss()\n",
       "          (embeddings): SequenceEmbeddingFeatures(\n",
       "            (filter_features): FilterFeatures()\n",
       "            (embedding_tables): ModuleDict(\n",
       "              (aid_): Embedding(1825326, 64, padding_idx=0)\n",
       "            )\n",
       "          )\n",
       "          (item_embedding_table): Embedding(1825326, 64, padding_idx=0)\n",
       "          (masking): CausalLanguageModeling()\n",
       "          (pre): Block(\n",
       "            (module): NextItemPredictionTask(\n",
       "              (item_embedding_table): Embedding(1825326, 64, padding_idx=0)\n",
       "              (log_softmax): LogSoftmax(dim=-1)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89180d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "\n",
    "\n",
    "# Set hyperparameters for training \n",
    "\n",
    "train_args = T4RecTrainingArguments(\n",
    "    data_loader_engine='nvtabular', \n",
    "    dataloader_drop_last = True,\n",
    "    gradient_accumulation_steps = 1,\n",
    "    per_device_train_batch_size = batch_size, \n",
    "    per_device_eval_batch_size = 128,\n",
    "    output_dir = \"./tmp-test\", \n",
    "    learning_rate=lr,\n",
    "    lr_scheduler_type=lr_scheduler, \n",
    "    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    max_sequence_length=20, \n",
    "    report_to = [],\n",
    "    logging_steps=1000,\n",
    "    save_steps=1000000,\n",
    "    no_cuda=False,\n",
    "    #resume_from_checkpoint='./tmp_2/checkpoint-50000'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1cf26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema2,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d50b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_shuffle(shuffle=bl_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6199996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 12367872\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 1024\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1024\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9459' max='12078' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9459/12078 28:16 < 07:49, 5.57 it/s, Epoch 0.78/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.083300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>4.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.372300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.209700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.065000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if using_test:\n",
    "    trainer.train_dataset_or_path = [path + 'data/train.parquet'] + [path + 'data/test.parquet']\n",
    "else:\n",
    "    trainer.train_dataset_or_path = [path + 'data/train.parquet']\n",
    "trainer.reset_lr_scheduler()\n",
    "trainer.train()\n",
    "#trainer.state.global_step +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38942fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_paths = [path + 'data/test.parquet']\n",
    "trainer.args.predict_top_k = 100\n",
    "trainer.test_dataset_or_path = [path + 'data/test.parquet']\n",
    "prediction = trainer.predict(eval_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6669c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(path + 'data/test.parquet', columns=['session'])\n",
    "df = df.head(prediction[0][0].shape[0])\n",
    "df['pred'] = prediction[0][0].tolist()\n",
    "df_aid = pd.read_parquet(path + '/data/map_aid.parquet')\n",
    "map_aid = df_aid.to_records()\n",
    "map_aids = {}\n",
    "\n",
    "for r in map_aid:\n",
    "    map_aids[r[1]] = r[2]\n",
    "    \n",
    "map_aids[1] = -1\n",
    "map_aids[0] = -1\n",
    "\n",
    "df['pred'] = df['pred'].apply(lambda x: [map_aids[y] for y in x])\n",
    "df.columns = ['session', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "372e6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = {}\n",
    "\n",
    "for target_type in ['clicks', 'carts', \"orders\"]:\n",
    "    test_labels = pd.read_parquet(path + '/test_labels.parquet')\n",
    "    test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "    test_labels = test_labels.loc[test_labels['type']==target_type]\n",
    "    test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "    test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "    test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "    recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "    recalls[target_type] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73cb8403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clicks': 0.43934416042476754,\n",
       " 'carts': 0.2944776295763296,\n",
       " 'orders': 0.4030834949707444}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a3b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e720e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = pd.read_parquet(path + '/test_labels.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6931a53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>796572</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>92401</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1561739</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>950341</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    session      aid    type\n",
       "0  11098528   796572  clicks\n",
       "1  11098528    92401  orders\n",
       "2  11098528  1561739  orders\n",
       "3  11098528   950341  orders\n",
       "4  11098529  1105029  clicks"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8444784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fccd25d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.603529 ,  9.584609 ,  9.4937725, ...,  8.045933 ,  8.042598 ,\n",
       "         8.034368 ],\n",
       "       [ 9.104875 ,  7.8496995,  7.3927402, ...,  5.7704325,  5.769855 ,\n",
       "         5.7587805],\n",
       "       [14.364313 , 13.633856 , 13.207083 , ...,  8.756059 ,  8.704534 ,\n",
       "         8.700096 ],\n",
       "       ...,\n",
       "       [10.337594 ,  7.860083 ,  7.7989454, ...,  6.551793 ,  6.548812 ,\n",
       "         6.546137 ],\n",
       "       [14.379154 , 12.915765 , 12.796582 , ...,  7.0632195,  7.0531487,\n",
       "         7.0494847],\n",
       "       [13.049289 ,  9.941049 ,  6.932467 , ...,  5.827901 ,  5.823332 ,\n",
       "         5.818209 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "576f94cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a31cf23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85bbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.from_pandas(df)\n",
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62378551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "230d1c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "198a5c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8370e2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ac2a710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d9ba2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d315552b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a71ae324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>[1289327, 1033148, 846545, 1722334, 1631509, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "      <td>[1105029, 258321, 1383767, 1171006, 644001, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "      <td>[264500, 409236, 877496, 583026, 1058185, 3641...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531</td>\n",
       "      <td>[1271998, 702610, 396199, 1565726, 524159, 448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532</td>\n",
       "      <td>[108125, 1673641, 470541, 317695, 7651, 123224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783732</th>\n",
       "      <td>12899774</td>\n",
       "      <td>[33035, 31490, 1226691, 771913, 1539309, 13596...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783733</th>\n",
       "      <td>12899775</td>\n",
       "      <td>[1743151, 1760714, 1550204, 1163166, 155954, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783734</th>\n",
       "      <td>12899776</td>\n",
       "      <td>[548599, 1470447, 1048957, 1598714, 1364783, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783735</th>\n",
       "      <td>12899777</td>\n",
       "      <td>[384045, 1688215, 1308634, 1281056, 395762, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783736</th>\n",
       "      <td>12899778</td>\n",
       "      <td>[561560, 1167224, 1852828, 1145314, 1731425, 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783737 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session                                               pred\n",
       "0        11098528  [1289327, 1033148, 846545, 1722334, 1631509, 4...\n",
       "1        11098529  [1105029, 258321, 1383767, 1171006, 644001, 12...\n",
       "2        11098530  [264500, 409236, 877496, 583026, 1058185, 3641...\n",
       "3        11098531  [1271998, 702610, 396199, 1565726, 524159, 448...\n",
       "4        11098532  [108125, 1673641, 470541, 317695, 7651, 123224...\n",
       "...           ...                                                ...\n",
       "1783732  12899774  [33035, 31490, 1226691, 771913, 1539309, 13596...\n",
       "1783733  12899775  [1743151, 1760714, 1550204, 1163166, 155954, 1...\n",
       "1783734  12899776  [548599, 1470447, 1048957, 1598714, 1364783, 4...\n",
       "1783735  12899777  [384045, 1688215, 1308634, 1281056, 395762, 14...\n",
       "1783736  12899778  [561560, 1167224, 1852828, 1145314, 1731425, 6...\n",
       "\n",
       "[1783737 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d468d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "488e35df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "068012e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['score'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4774\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4783\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4784\u001b[0m ):\n\u001b[1;32m   4785\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4787\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4904\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4905\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4908\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4150\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:4185\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4184\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4185\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4186\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{axis_name: new_axis})\n\u001b[1;32m   4188\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py:6017\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6017\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6018\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6019\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['score'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(['score'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e97839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['session', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e7e4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_labels = pd.read_parquet(path + '/test_labels.parquet')\n",
    "test_labels = test_labels[['session', 'aid', 'type']].groupby(['session', 'type']).agg(list).reset_index()\n",
    "test_labels = test_labels.loc[test_labels['type']=='clicks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a9f41a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>type</th>\n",
       "      <th>aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[796572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098529</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[1105029]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098530</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[264500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11098532</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[461190]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11098533</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[1697666]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189388</th>\n",
       "      <td>12899774</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[1399483]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189389</th>\n",
       "      <td>12899775</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[1760714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189390</th>\n",
       "      <td>12899776</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[1737908]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189391</th>\n",
       "      <td>12899777</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[384045]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189392</th>\n",
       "      <td>12899778</td>\n",
       "      <td>clicks</td>\n",
       "      <td>[32070]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1737986 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session    type        aid\n",
       "0        11098528  clicks   [796572]\n",
       "2        11098529  clicks  [1105029]\n",
       "4        11098530  clicks   [264500]\n",
       "7        11098532  clicks   [461190]\n",
       "9        11098533  clicks  [1697666]\n",
       "...           ...     ...        ...\n",
       "2189388  12899774  clicks  [1399483]\n",
       "2189389  12899775  clicks  [1760714]\n",
       "2189390  12899776  clicks  [1737908]\n",
       "2189391  12899777  clicks   [384045]\n",
       "2189392  12899778  clicks    [32070]\n",
       "\n",
       "[1737986 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ceba477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.merge(df, how='left', on=['session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca068b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.merge(df, how='left', on=['session'])\n",
    "test_labels['hits'] = test_labels.apply(lambda df: len(set(df.aid).intersection(set(df.labels))), axis=1)\n",
    "test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e0e26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels['gt_count'] = test_labels.aid.str.len().clip(0,20)\n",
    "recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c93c99c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4810194098226338"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a7b19d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306536"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels['hits'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f157435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34271a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a22ff08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  503,  1255,  1009, ...,   270,  4844,   467],\n",
       "       [    1,  1591,   511, ...,  2942, 12201,   288],\n",
       "       [  465,   962,   454, ...,  5244,  2192,  3930],\n",
       "       ...,\n",
       "       [    1,  4442,  6283, ..., 55952,  1295,  3330],\n",
       "       [ 2259,   569,  8203, ...,  3419,  3655,   662],\n",
       "       [    1,   102,   858, ...,  1394,    40,   245]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22b2d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = cudf.read_parquet(path + '/test_labels.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0550767",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_labels.merge(\n",
    "    test_labels.groupby(['session', 'type']).count().reset_index().rename(columns={'aid': 'no_gt'}),\n",
    "    how='left',\n",
    "    on=['session', 'type']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "908ef97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737986"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[test_labels['type']=='clicks'][['session', 'no_gt']].groupby(['session']).max().no_gt.clip(0,20).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b4c8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = cudf.read_parquet(path + '/data/map_aid.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071933d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6eaa245c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pred_19_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf_aid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpred_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py:101\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/core/dataframe.py:3474\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, on, left_on, right_on, left_index, right_index, how, sort, lsuffix, rsuffix, indicator, suffixes)\u001b[0m\n\u001b[1;32m   3380\u001b[0m \u001b[38;5;124;03m\"\"\"Merge GPU DataFrame objects by performing a database-style join\u001b[39;00m\n\u001b[1;32m   3381\u001b[0m \u001b[38;5;124;03moperation by columns or indexes.\u001b[39;00m\n\u001b[1;32m   3382\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;124;03mfrom both sides.\u001b[39;00m\n\u001b[1;32m   3472\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3473\u001b[0m \u001b[38;5;66;03m# Compute merge\u001b[39;00m\n\u001b[0;32m-> 3474\u001b[0m gdf_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gdf_result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/nvtx/nvtx.py:101\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    100\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/core/frame.py:2278\u001b[0m, in \u001b[0;36mFrame._merge\u001b[0;34m(self, right, on, left_on, right_on, left_index, right_index, how, sort, indicator, suffixes, lsuffix, rsuffix)\u001b[0m\n\u001b[1;32m   2274\u001b[0m     merge_cls \u001b[38;5;241m=\u001b[39m MergeSemi\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# TODO: the two isinstance checks below indicates that `_merge` should\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# not be defined in `Frame`, but in `IndexedFrame`.\u001b[39;00m\n\u001b[0;32m-> 2278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs_is_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseIndex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrhs_is_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseIndex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_merge\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/core/join/join.py:184\u001b[0m, in \u001b[0;36mMerge.perform_merge\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    181\u001b[0m right_join_cols \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m left_key, right_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_left_keys, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_right_keys):\n\u001b[0;32m--> 184\u001b[0m     lcol \u001b[38;5;241m=\u001b[39m \u001b[43mleft_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     rcol \u001b[38;5;241m=\u001b[39m right_key\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs)\n\u001b[1;32m    186\u001b[0m     lcol_casted, rcol_casted \u001b[38;5;241m=\u001b[39m _match_join_keys(lcol, rcol, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/core/join/_join_helpers.py:48\u001b[0m, in \u001b[0;36m_IndexIndexer.get\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Frame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ColumnBase:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/cudf/core/column_accessor.py:155\u001b[0m, in \u001b[0;36mColumnAccessor.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ColumnBase:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pred_19_'"
     ]
    }
   ],
   "source": [
    "df = df.merge(\n",
    "    df_aid,\n",
    "    how='left',\n",
    "    on='pred_' + str(i) + '_'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52c209bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783732</th>\n",
       "      <td>12899774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783733</th>\n",
       "      <td>12899775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783734</th>\n",
       "      <td>12899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783735</th>\n",
       "      <td>12899777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783736</th>\n",
       "      <td>12899778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783737 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session\n",
       "0        11098528\n",
       "1        11098529\n",
       "2        11098530\n",
       "3        11098531\n",
       "4        11098532\n",
       "...           ...\n",
       "1783732  12899774\n",
       "1783733  12899775\n",
       "1783734  12899776\n",
       "1783735  12899777\n",
       "1783736  12899778\n",
       "\n",
       "[1783737 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7e964bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid_</th>\n",
       "      <th>aid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1460571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>29735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>108125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1733943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>832192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562189</th>\n",
       "      <td>1562191</td>\n",
       "      <td>838504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562190</th>\n",
       "      <td>1562192</td>\n",
       "      <td>1774445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562191</th>\n",
       "      <td>1562193</td>\n",
       "      <td>816230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562192</th>\n",
       "      <td>1562194</td>\n",
       "      <td>1628178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562193</th>\n",
       "      <td>1562195</td>\n",
       "      <td>45910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1562194 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aid_      aid\n",
       "0              2  1460571\n",
       "1              3    29735\n",
       "2              4   108125\n",
       "3              5  1733943\n",
       "4              6   832192\n",
       "...          ...      ...\n",
       "1562189  1562191   838504\n",
       "1562190  1562192  1774445\n",
       "1562191  1562193   816230\n",
       "1562192  1562194  1628178\n",
       "1562193  1562195    45910\n",
       "\n",
       "[1562194 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81e5b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    df['pred_' + str(i) + '_'] = prediction[0][0][:, i]\n",
    "    df_aid.columns = ['pred_' + str(i) + '_', 'pred_' + str(i)]\n",
    "    df = df.merge(\n",
    "        df_aid,\n",
    "        how='left',\n",
    "        on='pred_' + str(i) + '_'\n",
    "    )\n",
    "    df['pred_' + str(i)] = df['pred_' + str(i)].fillna(-1)\n",
    "    df.drop(['pred_' + str(i) + '_'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2432654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "071a9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.melt(df, id_vars=['session'], value_vars=['pred_' + str(i) for i in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31ecc527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['variable'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69942254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e6774ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb4bc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(\n",
    "    test_labels.to_pandas(),\n",
    "    how='left',\n",
    "    on=['session']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdeb6082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     clicks\n",
       "8     orders\n",
       "11     carts\n",
       "Name: type, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcd7e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84102560",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = df[df['type']=='carts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9377388d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_281225/3145296611.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_clicks['hit'] = (df_clicks['aid']==df_clicks['value']).astype('int8')\n"
     ]
    }
   ],
   "source": [
    "df_clicks['hit'] = (df_clicks['aid']==df_clicks['value']).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da952b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks = df_clicks.groupby(['session']).agg({'no_gt': max, 'hit': sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "76035cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567021"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks.no_gt.clip(0,20).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c44b8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19326"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks.hit.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b66aa055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.048555589186800335"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "84380/1737802"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "16e3f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks['no_gt'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5276010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91ac9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>type</th>\n",
       "      <th>no_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11103159</td>\n",
       "      <td>1107392</td>\n",
       "      <td>carts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11103159</td>\n",
       "      <td>1105859</td>\n",
       "      <td>carts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11103159</td>\n",
       "      <td>518675</td>\n",
       "      <td>carts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11103159</td>\n",
       "      <td>157592</td>\n",
       "      <td>carts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11103159</td>\n",
       "      <td>1667358</td>\n",
       "      <td>carts</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621075</th>\n",
       "      <td>12899752</td>\n",
       "      <td>429407</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621076</th>\n",
       "      <td>12899754</td>\n",
       "      <td>922732</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621077</th>\n",
       "      <td>12899755</td>\n",
       "      <td>605</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621078</th>\n",
       "      <td>12899748</td>\n",
       "      <td>1503117</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621079</th>\n",
       "      <td>12899753</td>\n",
       "      <td>1517430</td>\n",
       "      <td>clicks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2621080 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session      aid    type  no_gt\n",
       "0        11103159  1107392   carts     16\n",
       "1        11103159  1105859   carts     16\n",
       "2        11103159   518675   carts     16\n",
       "3        11103159   157592   carts     16\n",
       "4        11103159  1667358   carts     16\n",
       "...           ...      ...     ...    ...\n",
       "2621075  12899752   429407  clicks      1\n",
       "2621076  12899754   922732  clicks      1\n",
       "2621077  12899755      605  clicks      1\n",
       "2621078  12899748  1503117  clicks      1\n",
       "2621079  12899753  1517430  clicks      1\n",
       "\n",
       "[2621080 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921edb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148e7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0006935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349259b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40be45b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098528</td>\n",
       "      <td>796572</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098528</td>\n",
       "      <td>92401</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098528</td>\n",
       "      <td>1561739</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098528</td>\n",
       "      <td>950341</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098529</td>\n",
       "      <td>1105029</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621075</th>\n",
       "      <td>12899774</td>\n",
       "      <td>1399483</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621076</th>\n",
       "      <td>12899775</td>\n",
       "      <td>1760714</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621077</th>\n",
       "      <td>12899776</td>\n",
       "      <td>1737908</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621078</th>\n",
       "      <td>12899777</td>\n",
       "      <td>384045</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621079</th>\n",
       "      <td>12899778</td>\n",
       "      <td>32070</td>\n",
       "      <td>clicks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2621080 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          session      aid    type\n",
       "0        11098528   796572  clicks\n",
       "1        11098528    92401  orders\n",
       "2        11098528  1561739  orders\n",
       "3        11098528   950341  orders\n",
       "4        11098529  1105029  clicks\n",
       "...           ...      ...     ...\n",
       "2621075  12899774  1399483  clicks\n",
       "2621076  12899775  1760714  clicks\n",
       "2621077  12899776  1737908  clicks\n",
       "2621078  12899777   384045  clicks\n",
       "2621079  12899778    32070  clicks\n",
       "\n",
       "[2621080 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5ef9671",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "incompatible index of inserted column with frame index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:10775\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  10774\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 10775\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m  10776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m  10777\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:324\u001b[0m, in \u001b[0;36mrewrite_axis_style_signature.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4772\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4771\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 4772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:4818\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4817\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 4818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4819\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   4820\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4597\u001b[0m, in \u001b[0;36mDataFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4597\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[1;32m   4599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4613\u001b[0m, in \u001b[0;36mDataFrame._reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   4603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reindex_index\u001b[39m(\n\u001b[1;32m   4604\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4605\u001b[0m     new_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4611\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4612\u001b[0m ):\n\u001b[0;32m-> 4613\u001b[0m     new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[1;32m   4615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   4617\u001b[0m         {\u001b[38;5;241m0\u001b[39m: [new_index, indexer]},\n\u001b[1;32m   4618\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   4619\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   4620\u001b[0m         allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   4621\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/multi.py:2533\u001b[0m, in \u001b[0;36mMultiIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2533\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2535\u001b[0m     \u001b[38;5;66;03m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/multi.py:202\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[0;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_or_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/multi.py:553\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[0;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[1;32m    551\u001b[0m         tuples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(tuples\u001b[38;5;241m.\u001b[39m_values)\n\u001b[0;32m--> 553\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuples_to_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/lib.pyx:2919\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mno_gt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m test_labels\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcount()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3602\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3600\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3601\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   3604\u001b[0m     is_list_like(value)\n\u001b[1;32m   3605\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3606\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   3607\u001b[0m ):\n\u001b[1;32m   3608\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3741\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3738\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mreindex(cols, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   3740\u001b[0m \u001b[38;5;66;03m# now align rows\u001b[39;00m\n\u001b[0;32m-> 3741\u001b[0m arraylike \u001b[38;5;241m=\u001b[39m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3742\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_mgr(key, arraylike)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:10782\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  10778\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m  10779\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[1;32m  10780\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m> 10782\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m  10783\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  10784\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m  10785\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value\n",
      "\u001b[0;31mTypeError\u001b[0m: incompatible index of inserted column with frame index"
     ]
    }
   ],
   "source": [
    "test_labels['no_gt'] = test_labels.groupby(['session', 'type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693a296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9712a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d0ee945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1783737, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64e280b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<merlin.io.dataset.Dataset at 0x7f2805bab6a0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_ddf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722c88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66d664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "??trainer.get_train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2aa3766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'session': tensor([    0,     1,     2,  ..., 66480, 66481, 66482], device='cuda:0',\n",
       "         dtype=torch.int32),\n",
       "  'type_': (tensor([1, 1, 1,  ..., 1, 2, 1], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'aid_': (tensor([1092338,  712999,   29865,  ..., 1624604,  181850,  181850],\n",
       "          device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'dummy': (tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'rank': (tensor([1, 2, 3,  ..., 5, 6, 7], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32))},\n",
       " None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67e14bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "??trainer.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05b1682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp test.pb ../../preprocess/data/schema.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d412978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.io import Dataset\n",
    "from merlin.loader.torch import Loader\n",
    "\n",
    "ds = Dataset([path + 'data/train.parquet'])\n",
    "loader = Loader(ds, batch_size=65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1855eb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac834016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3743aba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'session': tensor([    0,     1,     2,  ..., 66480, 66481, 66482], device='cuda:0',\n",
       "         dtype=torch.int32),\n",
       "  'type_': (tensor([1, 1, 1,  ..., 1, 2, 1], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'aid_': (tensor([1092338,  712999,   29865,  ..., 1624604,  181850,  181850],\n",
       "          device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'dummy': (tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32)),\n",
       "  'rank': (tensor([1, 2, 3,  ..., 5, 6, 7], device='cuda:0'),\n",
       "   tensor([[     0],\n",
       "           [    20],\n",
       "           [    40],\n",
       "           ...,\n",
       "           [858002],\n",
       "           [858004],\n",
       "           [858024]], device='cuda:0', dtype=torch.int32))},\n",
       " None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ef718d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a99d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3d830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
