{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1932484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1f513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08393145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_recall(sub, ty='clicks', file='./data/xgb_train_y.parquet'):\n",
    "    sub = sub.sort_values(['session', 'score'], ascending=[True, False])\n",
    "    sub['dummy'] = 1\n",
    "    sub['rank'] = sub.groupby(['session']).dummy.cumsum()\n",
    "    sub.drop(['dummy'], axis=1, inplace=True)\n",
    "    sub = sub[sub['rank']<21]\n",
    "    sub = sub[['session', 'cand']]\n",
    "    sub.columns = ['session', 'aid']\n",
    "    test_labels = cudf.read_parquet(file)\n",
    "    test_labels = test_labels[test_labels['type']==ty]\n",
    "    test_labels = test_labels.merge(\n",
    "        test_labels.groupby(['session', 'type']).count().reset_index().rename(columns={'aid': 'no_gt'}),\n",
    "        how='left',\n",
    "        on=['session', 'type']\n",
    "    )\n",
    "    sub['target'] = 1\n",
    "    sub.columns = ['session', 'aid', 'target']\n",
    "    test_labels = test_labels.merge(\n",
    "        sub[['session', 'aid', 'target']].drop_duplicates(['session', 'aid']),\n",
    "        how='left',\n",
    "        on=['session', 'aid']\n",
    "\n",
    "    )\n",
    "    test_labels['target'] = test_labels['target'].fillna(0)\n",
    "    test_labels = test_labels[test_labels['session'].isin(sub['session'])]\n",
    "    test_labels = test_labels.groupby(['session', 'aid']).agg({'no_gt': 'min', 'target': 'sum'}).reset_index()\n",
    "    recall = test_labels.target.sum()/test_labels.groupby(['session']).no_gt.min().clip(0,20).sum()\n",
    "    print(recall)\n",
    "    return(recall, test_labels.target.sum(), test_labels.groupby(['session']).no_gt.min().clip(0,20).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4769748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access './data/split/chunks_c/': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./data/split/chunks_c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f5dc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_parms = { \n",
    "    'max_depth':8, \n",
    "    'learning_rate':0.1, \n",
    "    'subsample':0.8,\n",
    "    'colsample_bytree':0.3, \n",
    "    'eval_metric':'logloss',\n",
    "    'objective':'binary:logistic',\n",
    "    'tree_method':'gpu_hist' \n",
    "}\n",
    "\n",
    "bl_sub = True\n",
    "bl_pos = True\n",
    "outputfolder = '24_XGB_Rerun_RedruceCandidate_DifferentWeights_Folds_ChrisCo_SameDay_v9'\n",
    "no_seeds = 10\n",
    "no_trees = 308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f30261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = 'carts'\n",
    "labels = cudf.read_parquet('./data/xgb_train_y.parquet')\n",
    "labels.columns = ['session', 'cand', 'type']\n",
    "labels['target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6febe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = sorted(glob.glob('./data/split/chunks/' + ty + '/chunk*.parquet'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce662ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data_folds/fold_0/split/chunks/carts/chunk_0.parquet',\n",
       " './data_folds/fold_0/split/chunks/carts/chunk_1.parquet',\n",
       " './data_folds/fold_1/split/chunks/carts/chunk_0.parquet',\n",
       " './data_folds/fold_1/split/chunks/carts/chunk_1.parquet',\n",
       " './data_folds/fold_2/split/chunks/carts/chunk_0.parquet',\n",
       " './data_folds/fold_2/split/chunks/carts/chunk_1.parquet',\n",
       " './data_folds/fold_3/split/chunks/carts/chunk_0.parquet',\n",
       " './data_folds/fold_3/split/chunks/carts/chunk_1.parquet',\n",
       " './data_folds/fold_4/split/chunks/carts/chunk_0.parquet',\n",
       " './data_folds/fold_4/split/chunks/carts/chunk_1.parquet']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y for x in [\n",
    "    sorted(glob.glob('./data_folds/fold_' + str(igfold2) + '/split/chunks/' + ty + '/chunk*.parquet'))\n",
    "    for igfold2 in range(0,5)\n",
    "] for y in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc283a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_filter = labels[(labels['type']=='orders')]['session'].drop_duplicates().to_pandas().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd42f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingore_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc994466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y']\n",
      "['./data_folds/fold_0/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_0/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_1/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_1/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_2/split/chunks_c/carts/chunk_0.parquet']\n",
      "['./data_folds/fold_0/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_0/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_1/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_1/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_2/split/chunks_c/carts/chunk_0.parquet']\n",
      "[]\n",
      "Recall Train: 0.7304464949219718\n",
      "iseed: 0\n",
      "[0]\ttrain-logloss:0.60094\n",
      "[10]\ttrain-logloss:0.19275\n",
      "[20]\ttrain-logloss:0.08325\n",
      "[30]\ttrain-logloss:0.04801\n",
      "[40]\ttrain-logloss:0.03652\n",
      "[50]\ttrain-logloss:0.03286\n",
      "[60]\ttrain-logloss:0.03163\n",
      "[70]\ttrain-logloss:0.03111\n",
      "[80]\ttrain-logloss:0.03083\n",
      "[90]\ttrain-logloss:0.03062\n",
      "[100]\ttrain-logloss:0.03045\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03017\n",
      "[130]\ttrain-logloss:0.03003\n",
      "[140]\ttrain-logloss:0.02991\n",
      "[150]\ttrain-logloss:0.02981\n",
      "[160]\ttrain-logloss:0.02969\n",
      "[170]\ttrain-logloss:0.02958\n",
      "[180]\ttrain-logloss:0.02948\n",
      "[190]\ttrain-logloss:0.02936\n",
      "[200]\ttrain-logloss:0.02926\n",
      "[210]\ttrain-logloss:0.02916\n",
      "[220]\ttrain-logloss:0.02906\n",
      "[230]\ttrain-logloss:0.02896\n",
      "[240]\ttrain-logloss:0.02886\n",
      "[250]\ttrain-logloss:0.02876\n",
      "[260]\ttrain-logloss:0.02869\n",
      "[270]\ttrain-logloss:0.02858\n",
      "[280]\ttrain-logloss:0.02849\n",
      "[290]\ttrain-logloss:0.02837\n",
      "[300]\ttrain-logloss:0.02828\n",
      "[307]\ttrain-logloss:0.02822\n",
      "iseed: 1\n",
      "[0]\ttrain-logloss:0.60079\n",
      "[10]\ttrain-logloss:0.19277\n",
      "[20]\ttrain-logloss:0.08326\n",
      "[30]\ttrain-logloss:0.04810\n",
      "[40]\ttrain-logloss:0.03659\n",
      "[50]\ttrain-logloss:0.03282\n",
      "[60]\ttrain-logloss:0.03159\n",
      "[70]\ttrain-logloss:0.03110\n",
      "[80]\ttrain-logloss:0.03081\n",
      "[90]\ttrain-logloss:0.03060\n",
      "[100]\ttrain-logloss:0.03044\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03017\n",
      "[130]\ttrain-logloss:0.03005\n",
      "[140]\ttrain-logloss:0.02992\n",
      "[150]\ttrain-logloss:0.02980\n",
      "[160]\ttrain-logloss:0.02969\n",
      "[170]\ttrain-logloss:0.02958\n",
      "[180]\ttrain-logloss:0.02947\n",
      "[190]\ttrain-logloss:0.02939\n",
      "[200]\ttrain-logloss:0.02930\n",
      "[210]\ttrain-logloss:0.02920\n",
      "[220]\ttrain-logloss:0.02911\n",
      "[230]\ttrain-logloss:0.02902\n",
      "[240]\ttrain-logloss:0.02891\n",
      "[250]\ttrain-logloss:0.02881\n",
      "[260]\ttrain-logloss:0.02872\n",
      "[270]\ttrain-logloss:0.02863\n",
      "[280]\ttrain-logloss:0.02854\n",
      "[290]\ttrain-logloss:0.02845\n",
      "[300]\ttrain-logloss:0.02838\n",
      "[307]\ttrain-logloss:0.02832\n",
      "iseed: 2\n",
      "[0]\ttrain-logloss:0.60080\n",
      "[10]\ttrain-logloss:0.19274\n",
      "[20]\ttrain-logloss:0.08324\n",
      "[30]\ttrain-logloss:0.04803\n",
      "[40]\ttrain-logloss:0.03652\n",
      "[50]\ttrain-logloss:0.03282\n",
      "[60]\ttrain-logloss:0.03158\n",
      "[70]\ttrain-logloss:0.03109\n",
      "[80]\ttrain-logloss:0.03081\n",
      "[90]\ttrain-logloss:0.03061\n",
      "[100]\ttrain-logloss:0.03045\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03017\n",
      "[130]\ttrain-logloss:0.03006\n",
      "[140]\ttrain-logloss:0.02991\n",
      "[150]\ttrain-logloss:0.02980\n",
      "[160]\ttrain-logloss:0.02968\n",
      "[170]\ttrain-logloss:0.02959\n",
      "[180]\ttrain-logloss:0.02947\n",
      "[190]\ttrain-logloss:0.02935\n",
      "[200]\ttrain-logloss:0.02926\n",
      "[210]\ttrain-logloss:0.02915\n",
      "[220]\ttrain-logloss:0.02904\n",
      "[230]\ttrain-logloss:0.02895\n",
      "[240]\ttrain-logloss:0.02886\n",
      "[250]\ttrain-logloss:0.02877\n",
      "[260]\ttrain-logloss:0.02869\n",
      "[270]\ttrain-logloss:0.02859\n",
      "[280]\ttrain-logloss:0.02851\n",
      "[290]\ttrain-logloss:0.02842\n",
      "[300]\ttrain-logloss:0.02833\n",
      "[307]\ttrain-logloss:0.02827\n",
      "iseed: 3\n",
      "[0]\ttrain-logloss:0.60080\n",
      "[10]\ttrain-logloss:0.19277\n",
      "[20]\ttrain-logloss:0.08329\n",
      "[30]\ttrain-logloss:0.04807\n",
      "[40]\ttrain-logloss:0.03652\n",
      "[50]\ttrain-logloss:0.03287\n",
      "[60]\ttrain-logloss:0.03163\n",
      "[70]\ttrain-logloss:0.03111\n",
      "[80]\ttrain-logloss:0.03083\n",
      "[90]\ttrain-logloss:0.03063\n",
      "[100]\ttrain-logloss:0.03046\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03015\n",
      "[130]\ttrain-logloss:0.03001\n",
      "[140]\ttrain-logloss:0.02989\n",
      "[150]\ttrain-logloss:0.02977\n",
      "[160]\ttrain-logloss:0.02967\n",
      "[170]\ttrain-logloss:0.02956\n",
      "[180]\ttrain-logloss:0.02946\n",
      "[190]\ttrain-logloss:0.02934\n",
      "[200]\ttrain-logloss:0.02924\n",
      "[210]\ttrain-logloss:0.02915\n",
      "[220]\ttrain-logloss:0.02906\n",
      "[230]\ttrain-logloss:0.02896\n",
      "[240]\ttrain-logloss:0.02886\n",
      "[250]\ttrain-logloss:0.02876\n",
      "[260]\ttrain-logloss:0.02866\n",
      "[270]\ttrain-logloss:0.02857\n",
      "[280]\ttrain-logloss:0.02847\n",
      "[290]\ttrain-logloss:0.02838\n",
      "[300]\ttrain-logloss:0.02829\n",
      "[307]\ttrain-logloss:0.02822\n",
      "iseed: 4\n",
      "[0]\ttrain-logloss:0.60084\n",
      "[10]\ttrain-logloss:0.19274\n",
      "[20]\ttrain-logloss:0.08326\n",
      "[30]\ttrain-logloss:0.04806\n",
      "[40]\ttrain-logloss:0.03650\n",
      "[50]\ttrain-logloss:0.03284\n",
      "[60]\ttrain-logloss:0.03160\n",
      "[70]\ttrain-logloss:0.03110\n",
      "[80]\ttrain-logloss:0.03081\n",
      "[90]\ttrain-logloss:0.03063\n",
      "[100]\ttrain-logloss:0.03046\n",
      "[110]\ttrain-logloss:0.03032\n",
      "[120]\ttrain-logloss:0.03019\n",
      "[130]\ttrain-logloss:0.03007\n",
      "[140]\ttrain-logloss:0.02994\n",
      "[150]\ttrain-logloss:0.02983\n",
      "[160]\ttrain-logloss:0.02973\n",
      "[170]\ttrain-logloss:0.02962\n",
      "[180]\ttrain-logloss:0.02950\n",
      "[190]\ttrain-logloss:0.02940\n",
      "[200]\ttrain-logloss:0.02930\n",
      "[210]\ttrain-logloss:0.02921\n",
      "[220]\ttrain-logloss:0.02911\n",
      "[230]\ttrain-logloss:0.02902\n",
      "[240]\ttrain-logloss:0.02894\n",
      "[250]\ttrain-logloss:0.02883\n",
      "[260]\ttrain-logloss:0.02871\n",
      "[270]\ttrain-logloss:0.02861\n",
      "[280]\ttrain-logloss:0.02851\n",
      "[290]\ttrain-logloss:0.02840\n",
      "[300]\ttrain-logloss:0.02831\n",
      "[307]\ttrain-logloss:0.02824\n",
      "iseed: 5\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19272\n",
      "[20]\ttrain-logloss:0.08320\n",
      "[30]\ttrain-logloss:0.04800\n",
      "[40]\ttrain-logloss:0.03651\n",
      "[50]\ttrain-logloss:0.03281\n",
      "[60]\ttrain-logloss:0.03158\n",
      "[70]\ttrain-logloss:0.03108\n",
      "[80]\ttrain-logloss:0.03082\n",
      "[90]\ttrain-logloss:0.03061\n",
      "[100]\ttrain-logloss:0.03045\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03015\n",
      "[130]\ttrain-logloss:0.03004\n",
      "[140]\ttrain-logloss:0.02993\n",
      "[150]\ttrain-logloss:0.02982\n",
      "[160]\ttrain-logloss:0.02971\n",
      "[170]\ttrain-logloss:0.02960\n",
      "[180]\ttrain-logloss:0.02951\n",
      "[190]\ttrain-logloss:0.02941\n",
      "[200]\ttrain-logloss:0.02930\n",
      "[210]\ttrain-logloss:0.02921\n",
      "[220]\ttrain-logloss:0.02912\n",
      "[230]\ttrain-logloss:0.02904\n",
      "[240]\ttrain-logloss:0.02895\n",
      "[250]\ttrain-logloss:0.02884\n",
      "[260]\ttrain-logloss:0.02875\n",
      "[270]\ttrain-logloss:0.02866\n",
      "[280]\ttrain-logloss:0.02858\n",
      "[290]\ttrain-logloss:0.02850\n",
      "[300]\ttrain-logloss:0.02842\n",
      "[307]\ttrain-logloss:0.02836\n",
      "iseed: 6\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19272\n",
      "[20]\ttrain-logloss:0.08328\n",
      "[30]\ttrain-logloss:0.04803\n",
      "[40]\ttrain-logloss:0.03653\n",
      "[50]\ttrain-logloss:0.03281\n",
      "[60]\ttrain-logloss:0.03160\n",
      "[70]\ttrain-logloss:0.03109\n",
      "[80]\ttrain-logloss:0.03081\n",
      "[90]\ttrain-logloss:0.03061\n",
      "[100]\ttrain-logloss:0.03044\n",
      "[110]\ttrain-logloss:0.03031\n",
      "[120]\ttrain-logloss:0.03018\n",
      "[130]\ttrain-logloss:0.03005\n",
      "[140]\ttrain-logloss:0.02994\n",
      "[150]\ttrain-logloss:0.02980\n",
      "[160]\ttrain-logloss:0.02969\n",
      "[170]\ttrain-logloss:0.02958\n",
      "[180]\ttrain-logloss:0.02948\n",
      "[190]\ttrain-logloss:0.02939\n",
      "[200]\ttrain-logloss:0.02928\n",
      "[210]\ttrain-logloss:0.02917\n",
      "[220]\ttrain-logloss:0.02906\n",
      "[230]\ttrain-logloss:0.02898\n",
      "[240]\ttrain-logloss:0.02889\n",
      "[250]\ttrain-logloss:0.02879\n",
      "[260]\ttrain-logloss:0.02869\n",
      "[270]\ttrain-logloss:0.02861\n",
      "[280]\ttrain-logloss:0.02852\n",
      "[290]\ttrain-logloss:0.02843\n",
      "[300]\ttrain-logloss:0.02834\n",
      "[307]\ttrain-logloss:0.02827\n",
      "iseed: 7\n",
      "[0]\ttrain-logloss:0.60078\n",
      "[10]\ttrain-logloss:0.19273\n",
      "[20]\ttrain-logloss:0.08329\n",
      "[30]\ttrain-logloss:0.04810\n",
      "[40]\ttrain-logloss:0.03658\n",
      "[50]\ttrain-logloss:0.03290\n",
      "[60]\ttrain-logloss:0.03161\n",
      "[70]\ttrain-logloss:0.03113\n",
      "[80]\ttrain-logloss:0.03085\n",
      "[90]\ttrain-logloss:0.03063\n",
      "[100]\ttrain-logloss:0.03047\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03018\n",
      "[130]\ttrain-logloss:0.03006\n",
      "[140]\ttrain-logloss:0.02992\n",
      "[150]\ttrain-logloss:0.02980\n",
      "[160]\ttrain-logloss:0.02969\n",
      "[170]\ttrain-logloss:0.02959\n",
      "[180]\ttrain-logloss:0.02947\n",
      "[190]\ttrain-logloss:0.02936\n",
      "[200]\ttrain-logloss:0.02926\n",
      "[210]\ttrain-logloss:0.02914\n",
      "[220]\ttrain-logloss:0.02905\n",
      "[230]\ttrain-logloss:0.02895\n",
      "[240]\ttrain-logloss:0.02887\n",
      "[250]\ttrain-logloss:0.02877\n",
      "[260]\ttrain-logloss:0.02867\n",
      "[270]\ttrain-logloss:0.02859\n",
      "[280]\ttrain-logloss:0.02850\n",
      "[290]\ttrain-logloss:0.02841\n",
      "[300]\ttrain-logloss:0.02832\n",
      "[307]\ttrain-logloss:0.02825\n",
      "iseed: 8\n",
      "[0]\ttrain-logloss:0.60080\n",
      "[10]\ttrain-logloss:0.19270\n",
      "[20]\ttrain-logloss:0.08325\n",
      "[30]\ttrain-logloss:0.04807\n",
      "[40]\ttrain-logloss:0.03654\n",
      "[50]\ttrain-logloss:0.03285\n",
      "[60]\ttrain-logloss:0.03160\n",
      "[70]\ttrain-logloss:0.03111\n",
      "[80]\ttrain-logloss:0.03083\n",
      "[90]\ttrain-logloss:0.03063\n",
      "[100]\ttrain-logloss:0.03045\n",
      "[110]\ttrain-logloss:0.03030\n",
      "[120]\ttrain-logloss:0.03015\n",
      "[130]\ttrain-logloss:0.03002\n",
      "[140]\ttrain-logloss:0.02990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150]\ttrain-logloss:0.02979\n",
      "[160]\ttrain-logloss:0.02967\n",
      "[170]\ttrain-logloss:0.02956\n",
      "[180]\ttrain-logloss:0.02946\n",
      "[190]\ttrain-logloss:0.02935\n",
      "[200]\ttrain-logloss:0.02925\n",
      "[210]\ttrain-logloss:0.02915\n",
      "[220]\ttrain-logloss:0.02904\n",
      "[230]\ttrain-logloss:0.02894\n",
      "[240]\ttrain-logloss:0.02885\n",
      "[250]\ttrain-logloss:0.02875\n",
      "[260]\ttrain-logloss:0.02866\n",
      "[270]\ttrain-logloss:0.02856\n",
      "[280]\ttrain-logloss:0.02848\n",
      "[290]\ttrain-logloss:0.02839\n",
      "[300]\ttrain-logloss:0.02831\n",
      "[307]\ttrain-logloss:0.02825\n",
      "iseed: 9\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19274\n",
      "[20]\ttrain-logloss:0.08324\n",
      "[30]\ttrain-logloss:0.04807\n",
      "[40]\ttrain-logloss:0.03652\n",
      "[50]\ttrain-logloss:0.03285\n",
      "[60]\ttrain-logloss:0.03163\n",
      "[70]\ttrain-logloss:0.03113\n",
      "[80]\ttrain-logloss:0.03084\n",
      "[90]\ttrain-logloss:0.03063\n",
      "[100]\ttrain-logloss:0.03045\n",
      "[110]\ttrain-logloss:0.03031\n",
      "[120]\ttrain-logloss:0.03015\n",
      "[130]\ttrain-logloss:0.03003\n",
      "[140]\ttrain-logloss:0.02991\n",
      "[150]\ttrain-logloss:0.02980\n",
      "[160]\ttrain-logloss:0.02971\n",
      "[170]\ttrain-logloss:0.02960\n",
      "[180]\ttrain-logloss:0.02949\n",
      "[190]\ttrain-logloss:0.02938\n",
      "[200]\ttrain-logloss:0.02928\n",
      "[210]\ttrain-logloss:0.02918\n",
      "[220]\ttrain-logloss:0.02908\n",
      "[230]\ttrain-logloss:0.02898\n",
      "[240]\ttrain-logloss:0.02888\n",
      "[250]\ttrain-logloss:0.02880\n",
      "[260]\ttrain-logloss:0.02870\n",
      "[270]\ttrain-logloss:0.02861\n",
      "[280]\ttrain-logloss:0.02850\n",
      "[290]\ttrain-logloss:0.02842\n",
      "[300]\ttrain-logloss:0.02832\n",
      "[307]\ttrain-logloss:0.02825\n",
      "['./data_folds/fold_2/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_3/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_3/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_4/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_4/split/chunks_c/carts/chunk_1.parquet']\n",
      "['./data_folds/fold_2/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_3/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_3/split/chunks_c/carts/chunk_1.parquet', './data_folds/fold_4/split/chunks_c/carts/chunk_0.parquet', './data_folds/fold_4/split/chunks_c/carts/chunk_1.parquet']\n",
      "[]\n",
      "Recall Train: 0.7276234330243015\n",
      "iseed: 0\n",
      "[0]\ttrain-logloss:0.60095\n",
      "[10]\ttrain-logloss:0.19280\n",
      "[20]\ttrain-logloss:0.08334\n",
      "[30]\ttrain-logloss:0.04812\n",
      "[40]\ttrain-logloss:0.03665\n",
      "[50]\ttrain-logloss:0.03301\n",
      "[60]\ttrain-logloss:0.03179\n",
      "[70]\ttrain-logloss:0.03126\n",
      "[80]\ttrain-logloss:0.03100\n",
      "[90]\ttrain-logloss:0.03079\n",
      "[100]\ttrain-logloss:0.03061\n",
      "[110]\ttrain-logloss:0.03048\n",
      "[120]\ttrain-logloss:0.03035\n",
      "[130]\ttrain-logloss:0.03023\n",
      "[140]\ttrain-logloss:0.03014\n",
      "[150]\ttrain-logloss:0.03003\n",
      "[160]\ttrain-logloss:0.02992\n",
      "[170]\ttrain-logloss:0.02979\n",
      "[180]\ttrain-logloss:0.02968\n",
      "[190]\ttrain-logloss:0.02958\n",
      "[200]\ttrain-logloss:0.02949\n",
      "[210]\ttrain-logloss:0.02939\n",
      "[220]\ttrain-logloss:0.02928\n",
      "[230]\ttrain-logloss:0.02918\n",
      "[240]\ttrain-logloss:0.02909\n",
      "[250]\ttrain-logloss:0.02899\n",
      "[260]\ttrain-logloss:0.02890\n",
      "[270]\ttrain-logloss:0.02882\n",
      "[280]\ttrain-logloss:0.02873\n",
      "[290]\ttrain-logloss:0.02864\n",
      "[300]\ttrain-logloss:0.02854\n",
      "[307]\ttrain-logloss:0.02849\n",
      "iseed: 1\n",
      "[0]\ttrain-logloss:0.60080\n",
      "[10]\ttrain-logloss:0.19282\n",
      "[20]\ttrain-logloss:0.08334\n",
      "[30]\ttrain-logloss:0.04820\n",
      "[40]\ttrain-logloss:0.03671\n",
      "[50]\ttrain-logloss:0.03295\n",
      "[60]\ttrain-logloss:0.03173\n",
      "[70]\ttrain-logloss:0.03125\n",
      "[80]\ttrain-logloss:0.03097\n",
      "[90]\ttrain-logloss:0.03076\n",
      "[100]\ttrain-logloss:0.03060\n",
      "[110]\ttrain-logloss:0.03049\n",
      "[120]\ttrain-logloss:0.03035\n",
      "[130]\ttrain-logloss:0.03024\n",
      "[140]\ttrain-logloss:0.03013\n",
      "[150]\ttrain-logloss:0.03003\n",
      "[160]\ttrain-logloss:0.02991\n",
      "[170]\ttrain-logloss:0.02980\n",
      "[180]\ttrain-logloss:0.02969\n",
      "[190]\ttrain-logloss:0.02958\n",
      "[200]\ttrain-logloss:0.02949\n",
      "[210]\ttrain-logloss:0.02939\n",
      "[220]\ttrain-logloss:0.02929\n",
      "[230]\ttrain-logloss:0.02918\n",
      "[240]\ttrain-logloss:0.02907\n",
      "[250]\ttrain-logloss:0.02896\n",
      "[260]\ttrain-logloss:0.02883\n",
      "[270]\ttrain-logloss:0.02876\n",
      "[280]\ttrain-logloss:0.02869\n",
      "[290]\ttrain-logloss:0.02860\n",
      "[300]\ttrain-logloss:0.02851\n",
      "[307]\ttrain-logloss:0.02845\n",
      "iseed: 2\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19279\n",
      "[20]\ttrain-logloss:0.08331\n",
      "[30]\ttrain-logloss:0.04813\n",
      "[40]\ttrain-logloss:0.03665\n",
      "[50]\ttrain-logloss:0.03296\n",
      "[60]\ttrain-logloss:0.03172\n",
      "[70]\ttrain-logloss:0.03123\n",
      "[80]\ttrain-logloss:0.03096\n",
      "[90]\ttrain-logloss:0.03077\n",
      "[100]\ttrain-logloss:0.03061\n",
      "[110]\ttrain-logloss:0.03046\n",
      "[120]\ttrain-logloss:0.03033\n",
      "[130]\ttrain-logloss:0.03021\n",
      "[140]\ttrain-logloss:0.03010\n",
      "[150]\ttrain-logloss:0.02996\n",
      "[160]\ttrain-logloss:0.02987\n",
      "[170]\ttrain-logloss:0.02976\n",
      "[180]\ttrain-logloss:0.02964\n",
      "[190]\ttrain-logloss:0.02953\n",
      "[200]\ttrain-logloss:0.02942\n",
      "[210]\ttrain-logloss:0.02933\n",
      "[220]\ttrain-logloss:0.02923\n",
      "[230]\ttrain-logloss:0.02912\n",
      "[240]\ttrain-logloss:0.02902\n",
      "[250]\ttrain-logloss:0.02896\n",
      "[260]\ttrain-logloss:0.02886\n",
      "[270]\ttrain-logloss:0.02877\n",
      "[280]\ttrain-logloss:0.02868\n",
      "[290]\ttrain-logloss:0.02859\n",
      "[300]\ttrain-logloss:0.02851\n",
      "[307]\ttrain-logloss:0.02845\n",
      "iseed: 3\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19282\n",
      "[20]\ttrain-logloss:0.08338\n",
      "[30]\ttrain-logloss:0.04818\n",
      "[40]\ttrain-logloss:0.03666\n",
      "[50]\ttrain-logloss:0.03301\n",
      "[60]\ttrain-logloss:0.03178\n",
      "[70]\ttrain-logloss:0.03127\n",
      "[80]\ttrain-logloss:0.03100\n",
      "[90]\ttrain-logloss:0.03082\n",
      "[100]\ttrain-logloss:0.03068\n",
      "[110]\ttrain-logloss:0.03051\n",
      "[120]\ttrain-logloss:0.03039\n",
      "[130]\ttrain-logloss:0.03027\n",
      "[140]\ttrain-logloss:0.03016\n",
      "[150]\ttrain-logloss:0.03004\n",
      "[160]\ttrain-logloss:0.02995\n",
      "[170]\ttrain-logloss:0.02984\n",
      "[180]\ttrain-logloss:0.02975\n",
      "[190]\ttrain-logloss:0.02965\n",
      "[200]\ttrain-logloss:0.02954\n",
      "[210]\ttrain-logloss:0.02944\n",
      "[220]\ttrain-logloss:0.02935\n",
      "[230]\ttrain-logloss:0.02925\n",
      "[240]\ttrain-logloss:0.02916\n",
      "[250]\ttrain-logloss:0.02905\n",
      "[260]\ttrain-logloss:0.02898\n",
      "[270]\ttrain-logloss:0.02888\n",
      "[280]\ttrain-logloss:0.02879\n",
      "[290]\ttrain-logloss:0.02869\n",
      "[300]\ttrain-logloss:0.02860\n",
      "[307]\ttrain-logloss:0.02854\n",
      "iseed: 4\n",
      "[0]\ttrain-logloss:0.60084\n",
      "[10]\ttrain-logloss:0.19280\n",
      "[20]\ttrain-logloss:0.08335\n",
      "[30]\ttrain-logloss:0.04817\n",
      "[40]\ttrain-logloss:0.03662\n",
      "[50]\ttrain-logloss:0.03297\n",
      "[60]\ttrain-logloss:0.03173\n",
      "[70]\ttrain-logloss:0.03124\n",
      "[80]\ttrain-logloss:0.03096\n",
      "[90]\ttrain-logloss:0.03077\n",
      "[100]\ttrain-logloss:0.03061\n",
      "[110]\ttrain-logloss:0.03047\n",
      "[120]\ttrain-logloss:0.03035\n",
      "[130]\ttrain-logloss:0.03022\n",
      "[140]\ttrain-logloss:0.03013\n",
      "[150]\ttrain-logloss:0.03002\n",
      "[160]\ttrain-logloss:0.02992\n",
      "[170]\ttrain-logloss:0.02981\n",
      "[180]\ttrain-logloss:0.02970\n",
      "[190]\ttrain-logloss:0.02960\n",
      "[200]\ttrain-logloss:0.02949\n",
      "[210]\ttrain-logloss:0.02939\n",
      "[220]\ttrain-logloss:0.02930\n",
      "[230]\ttrain-logloss:0.02919\n",
      "[240]\ttrain-logloss:0.02911\n",
      "[250]\ttrain-logloss:0.02902\n",
      "[260]\ttrain-logloss:0.02895\n",
      "[270]\ttrain-logloss:0.02884\n",
      "[280]\ttrain-logloss:0.02875\n",
      "[290]\ttrain-logloss:0.02865\n",
      "[300]\ttrain-logloss:0.02856\n",
      "[307]\ttrain-logloss:0.02850\n",
      "iseed: 5\n",
      "[0]\ttrain-logloss:0.60082\n",
      "[10]\ttrain-logloss:0.19277\n",
      "[20]\ttrain-logloss:0.08328\n",
      "[30]\ttrain-logloss:0.04810\n",
      "[40]\ttrain-logloss:0.03663\n",
      "[50]\ttrain-logloss:0.03294\n",
      "[60]\ttrain-logloss:0.03172\n",
      "[70]\ttrain-logloss:0.03123\n",
      "[80]\ttrain-logloss:0.03097\n",
      "[90]\ttrain-logloss:0.03076\n",
      "[100]\ttrain-logloss:0.03059\n",
      "[110]\ttrain-logloss:0.03046\n",
      "[120]\ttrain-logloss:0.03032\n",
      "[130]\ttrain-logloss:0.03020\n",
      "[140]\ttrain-logloss:0.03008\n",
      "[150]\ttrain-logloss:0.02997\n",
      "[160]\ttrain-logloss:0.02987\n",
      "[170]\ttrain-logloss:0.02975\n",
      "[180]\ttrain-logloss:0.02964\n",
      "[190]\ttrain-logloss:0.02954\n",
      "[200]\ttrain-logloss:0.02944\n",
      "[210]\ttrain-logloss:0.02933\n",
      "[220]\ttrain-logloss:0.02924\n",
      "[230]\ttrain-logloss:0.02913\n",
      "[240]\ttrain-logloss:0.02905\n",
      "[250]\ttrain-logloss:0.02897\n",
      "[260]\ttrain-logloss:0.02887\n",
      "[270]\ttrain-logloss:0.02877\n",
      "[280]\ttrain-logloss:0.02867\n",
      "[290]\ttrain-logloss:0.02858\n",
      "[300]\ttrain-logloss:0.02849\n",
      "[307]\ttrain-logloss:0.02842\n",
      "iseed: 6\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19276\n",
      "[20]\ttrain-logloss:0.08335\n",
      "[30]\ttrain-logloss:0.04813\n",
      "[40]\ttrain-logloss:0.03666\n",
      "[50]\ttrain-logloss:0.03295\n",
      "[60]\ttrain-logloss:0.03173\n",
      "[70]\ttrain-logloss:0.03123\n",
      "[80]\ttrain-logloss:0.03094\n",
      "[90]\ttrain-logloss:0.03076\n",
      "[100]\ttrain-logloss:0.03061\n",
      "[110]\ttrain-logloss:0.03047\n",
      "[120]\ttrain-logloss:0.03035\n",
      "[130]\ttrain-logloss:0.03023\n",
      "[140]\ttrain-logloss:0.03010\n",
      "[150]\ttrain-logloss:0.02999\n",
      "[160]\ttrain-logloss:0.02988\n",
      "[170]\ttrain-logloss:0.02978\n",
      "[180]\ttrain-logloss:0.02966\n",
      "[190]\ttrain-logloss:0.02954\n",
      "[200]\ttrain-logloss:0.02943\n",
      "[210]\ttrain-logloss:0.02933\n",
      "[220]\ttrain-logloss:0.02925\n",
      "[230]\ttrain-logloss:0.02914\n",
      "[240]\ttrain-logloss:0.02903\n",
      "[250]\ttrain-logloss:0.02893\n",
      "[260]\ttrain-logloss:0.02884\n",
      "[270]\ttrain-logloss:0.02874\n",
      "[280]\ttrain-logloss:0.02864\n",
      "[290]\ttrain-logloss:0.02855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain-logloss:0.02847\n",
      "[307]\ttrain-logloss:0.02840\n",
      "iseed: 7\n",
      "[0]\ttrain-logloss:0.60078\n",
      "[10]\ttrain-logloss:0.19278\n",
      "[20]\ttrain-logloss:0.08336\n",
      "[30]\ttrain-logloss:0.04820\n",
      "[40]\ttrain-logloss:0.03670\n",
      "[50]\ttrain-logloss:0.03303\n",
      "[60]\ttrain-logloss:0.03175\n",
      "[70]\ttrain-logloss:0.03127\n",
      "[80]\ttrain-logloss:0.03099\n",
      "[90]\ttrain-logloss:0.03078\n",
      "[100]\ttrain-logloss:0.03062\n",
      "[110]\ttrain-logloss:0.03048\n",
      "[120]\ttrain-logloss:0.03034\n",
      "[130]\ttrain-logloss:0.03021\n",
      "[140]\ttrain-logloss:0.03009\n",
      "[150]\ttrain-logloss:0.02997\n",
      "[160]\ttrain-logloss:0.02987\n",
      "[170]\ttrain-logloss:0.02978\n",
      "[180]\ttrain-logloss:0.02968\n",
      "[190]\ttrain-logloss:0.02956\n",
      "[200]\ttrain-logloss:0.02945\n",
      "[210]\ttrain-logloss:0.02935\n",
      "[220]\ttrain-logloss:0.02926\n",
      "[230]\ttrain-logloss:0.02917\n",
      "[240]\ttrain-logloss:0.02909\n",
      "[250]\ttrain-logloss:0.02898\n",
      "[260]\ttrain-logloss:0.02889\n",
      "[270]\ttrain-logloss:0.02881\n",
      "[280]\ttrain-logloss:0.02872\n",
      "[290]\ttrain-logloss:0.02863\n",
      "[300]\ttrain-logloss:0.02852\n",
      "[307]\ttrain-logloss:0.02846\n",
      "iseed: 8\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19274\n",
      "[20]\ttrain-logloss:0.08332\n",
      "[30]\ttrain-logloss:0.04817\n",
      "[40]\ttrain-logloss:0.03667\n",
      "[50]\ttrain-logloss:0.03300\n",
      "[60]\ttrain-logloss:0.03174\n",
      "[70]\ttrain-logloss:0.03125\n",
      "[80]\ttrain-logloss:0.03099\n",
      "[90]\ttrain-logloss:0.03079\n",
      "[100]\ttrain-logloss:0.03063\n",
      "[110]\ttrain-logloss:0.03049\n",
      "[120]\ttrain-logloss:0.03037\n",
      "[130]\ttrain-logloss:0.03025\n",
      "[140]\ttrain-logloss:0.03012\n",
      "[150]\ttrain-logloss:0.03001\n",
      "[160]\ttrain-logloss:0.02990\n",
      "[170]\ttrain-logloss:0.02979\n",
      "[180]\ttrain-logloss:0.02968\n",
      "[190]\ttrain-logloss:0.02960\n",
      "[200]\ttrain-logloss:0.02952\n",
      "[210]\ttrain-logloss:0.02945\n",
      "[220]\ttrain-logloss:0.02935\n",
      "[230]\ttrain-logloss:0.02925\n",
      "[240]\ttrain-logloss:0.02915\n",
      "[250]\ttrain-logloss:0.02905\n",
      "[260]\ttrain-logloss:0.02896\n",
      "[270]\ttrain-logloss:0.02887\n",
      "[280]\ttrain-logloss:0.02877\n",
      "[290]\ttrain-logloss:0.02869\n",
      "[300]\ttrain-logloss:0.02860\n",
      "[307]\ttrain-logloss:0.02855\n",
      "iseed: 9\n",
      "[0]\ttrain-logloss:0.60081\n",
      "[10]\ttrain-logloss:0.19279\n",
      "[20]\ttrain-logloss:0.08333\n",
      "[30]\ttrain-logloss:0.04819\n",
      "[40]\ttrain-logloss:0.03665\n",
      "[50]\ttrain-logloss:0.03299\n",
      "[60]\ttrain-logloss:0.03177\n",
      "[70]\ttrain-logloss:0.03127\n",
      "[80]\ttrain-logloss:0.03098\n",
      "[90]\ttrain-logloss:0.03078\n",
      "[100]\ttrain-logloss:0.03061\n",
      "[110]\ttrain-logloss:0.03047\n",
      "[120]\ttrain-logloss:0.03034\n",
      "[130]\ttrain-logloss:0.03022\n",
      "[140]\ttrain-logloss:0.03010\n",
      "[150]\ttrain-logloss:0.02999\n",
      "[160]\ttrain-logloss:0.02989\n",
      "[170]\ttrain-logloss:0.02979\n",
      "[180]\ttrain-logloss:0.02970\n",
      "[190]\ttrain-logloss:0.02959\n",
      "[200]\ttrain-logloss:0.02949\n",
      "[210]\ttrain-logloss:0.02938\n",
      "[220]\ttrain-logloss:0.02928\n",
      "[230]\ttrain-logloss:0.02918\n",
      "[240]\ttrain-logloss:0.02908\n",
      "[250]\ttrain-logloss:0.02898\n",
      "[260]\ttrain-logloss:0.02888\n",
      "[270]\ttrain-logloss:0.02879\n",
      "[280]\ttrain-logloss:0.02869\n",
      "[290]\ttrain-logloss:0.02860\n",
      "[300]\ttrain-logloss:0.02851\n",
      "[307]\ttrain-logloss:0.02845\n",
      "CPU times: user 20min 29s, sys: 2min 34s, total: 23min 3s\n",
      "Wall time: 15min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "models = []\n",
    "hist_recall = []\n",
    "total_no_hit = 0\n",
    "total_no_gt = 0\n",
    "for igfold in range(1):\n",
    "    files = ['x', 'y']\n",
    "    print(files)\n",
    "    for ifile, file in enumerate(files):\n",
    "        if bl_sub:\n",
    "            if ty == 'clicks':\n",
    "                test_files = []\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]]\n",
    "            elif ty == 'carts':\n",
    "                test_files = []\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]]\n",
    "            elif ty == 'orders':\n",
    "                test_files = []\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]]\n",
    "            else:\n",
    "                assert 0!=0\n",
    "            \n",
    "            train_files = sorted([\n",
    "                y for x in [\n",
    "                    sorted(glob.glob('./data_folds/fold_' + str(igfold2) + '/split/chunks_c/' + ty + '/chunk*.parquet'))\n",
    "                    for igfold2 in range(0,5)\n",
    "                ] for y in x\n",
    "            ])\n",
    "            \n",
    "            step=5\n",
    "            train_files_list = []\n",
    "            for i in range(0, len(train_files), step):\n",
    "                x = i\n",
    "                train_files_list.append(train_files[x:x+step])\n",
    "            train_files = train_files_list[ifile]\n",
    "            print(train_files)\n",
    "            \n",
    "            if ty == 'clicks':\n",
    "                df_train = pd.concat([\n",
    "                    pd.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "            elif ty == 'carts':\n",
    "                df_train = pd.concat([\n",
    "                    pd.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "            elif ty == 'orders':\n",
    "                df_train = pd.concat([\n",
    "                    pd.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "            df_train = df_train[~(df_train['session'].isin(session_filter))]\n",
    "        else:\n",
    "            if ty == 'clicks':\n",
    "                test_files = files[ifile]\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]][0:1]\n",
    "            elif ty == 'carts':\n",
    "                test_files = files[ifile]\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]][0:1]\n",
    "            elif ty == 'orders':\n",
    "                test_files = files[ifile]\n",
    "                train_files = [files[x] for x in [(ifile+i+1)%len(files) for i in range(len(files))]][0:1]\n",
    "            else:\n",
    "                assert 0!=0\n",
    "            \n",
    "            train_files = [\n",
    "                y for x in [\n",
    "                    sorted(glob.glob('./data_folds/fold_' + str(igfold2) + '/split/chunks_c/' + ty + '/chunk*.parquet'))\n",
    "                    for igfold2 in range(0,5)\n",
    "                ] for y in x if y not in test_files]\n",
    "            \n",
    "            if ty == 'clicks':\n",
    "                df_test = pd.read_parquet(test_files)\n",
    "                df_train = pd.concat([\n",
    "                    pd.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "            elif ty == 'carts':\n",
    "                df_test = cudf.read_parquet(test_files)\n",
    "                df_train = cudf.concat([\n",
    "                    cudf.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "            elif ty == 'orders':\n",
    "                df_test = pd.read_parquet(test_files)\n",
    "                df_train = pd.concat([\n",
    "                    pd.read_parquet(x) for x in train_files\n",
    "                ])\n",
    "\n",
    "        print(train_files)\n",
    "        print(test_files)\n",
    "\n",
    "        if bl_pos:\n",
    "            df_train = df_train[df_train['session'].isin(\n",
    "                df_train[df_train['target']==1]['session'].drop_duplicates().values\n",
    "            )]\n",
    "\n",
    "        train_cols = [x for x in df_train.columns if x not in [\n",
    "            'session', 'cand', 'target', 'target_clicks', 'target_carts', 'target_orders'\n",
    "        ] + ingore_cols]\n",
    "\n",
    "        print('Recall Train: ' + str(df_train[df_train['target']==1].shape[0]/labels[\n",
    "        (labels['session'].isin(df_train['session'].drop_duplicates()))&(labels['type']==ty)\n",
    "    ].shape[0]))\n",
    "        if not bl_sub:\n",
    "            print('Recall Test: ' + str(df_test[df_test['target']==1].shape[0]/labels[\n",
    "            (labels['session'].isin(df_test['session'].drop_duplicates()))&(labels['type']==ty)\n",
    "        ].shape[0]))\n",
    "\n",
    "        dtrain = xgb.DMatrix(data=df_train[train_cols].values,label=df_train['target'].values)\n",
    "        if not bl_sub:\n",
    "            dtest =  xgb.DMatrix(data=df_test[train_cols].values, label=df_test['target'].values)\n",
    "            df_test['score'] = 0.0\n",
    "\n",
    "        del df_train\n",
    "        gc.collect()\n",
    "\n",
    "        for iseed in range(no_seeds):\n",
    "            print('iseed: ' + str(iseed))\n",
    "            xgb_parms['seed'] = iseed\n",
    "            if bl_sub:\n",
    "                model = xgb.train(\n",
    "                    xgb_parms, \n",
    "                    dtrain=dtrain,\n",
    "                    evals=[(dtrain,'train')],\n",
    "                    num_boost_round=no_trees,\n",
    "                    verbose_eval=10\n",
    "                )\n",
    "            else:\n",
    "                model = xgb.train(\n",
    "                    xgb_parms, \n",
    "                    dtrain=dtrain,\n",
    "                    evals=[(dtest,'test')],\n",
    "                    num_boost_round=no_trees,\n",
    "                    verbose_eval=10,\n",
    "                    early_stopping_rounds=50\n",
    "                )\n",
    "                df_test['score'] += model.predict(dtest)\n",
    "            models.append(model)\n",
    "        del dtrain\n",
    "        \n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3371640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_seeds = len(models)\n",
    "ifile = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae8d29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03215724",
   "metadata": {},
   "outputs": [],
   "source": [
    "for igfold2 in range(5):\n",
    "    os.system('mkdir -p ' + './data_folds/fold_' + str(igfold2) + '/split/sub_c_2/')\n",
    "    os.system('mkdir -p ' + './data_folds/fold_' + str(igfold2) + '/split/chunks_c_2/' + 'orders' + '/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595330b4",
   "metadata": {},
   "source": [
    "Predict Orders Dataset and add carts score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e64a6b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isubfile: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/cudf/core/single_column_frame.py:345: FutureWarning: Binary operations between host objects such as <class 'numpy.ndarray'> and <class 'cudf.core.series.Series'> are deprecated and will be removed in a future release. Please convert it to a cudf object before performing the operation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isubfile: 1\n",
      "isubfile: 0\n",
      "isubfile: 1\n",
      "isubfile: 0\n",
      "isubfile: 1\n",
      "isubfile: 0\n",
      "isubfile: 1\n",
      "isubfile: 0\n",
      "isubfile: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for igfold2 in range(5):\n",
    "    if ifile==0:\n",
    "        sssfiles = glob.glob('./data_folds/fold_' + str(igfold2) + '/split/chunks_c/' + 'orders' + '/chunk*.parquet')\n",
    "    else:\n",
    "        sssfiles = glob.glob('./data_folds/fold_' + str(igfold2) + '/split/chunks_c_2/' + 'orders' + '/chunk*.parquet')\n",
    "    for isubfile, sub_file in enumerate(sssfiles):\n",
    "        print('isubfile: ' + str(isubfile))\n",
    "        df_sub = cudf.read_parquet(sub_file).fillna(-999)\n",
    "        if 'xgb_ca_score' not in df_sub.columns:\n",
    "            df_sub['xgb_ca_score'] = 0.0\n",
    "        \n",
    "        dsub = xgb.DMatrix(data=df_sub[train_cols].values)\n",
    "        for iseed in range(no_seeds):\n",
    "            df_sub['xgb_ca_score'] = df_sub['xgb_ca_score'] + models[iseed].predict(dsub)/no_seeds\n",
    "        if ifile==0:\n",
    "            df_sub.to_parquet(\n",
    "                sub_file.replace('/chunks_c/', '/chunks_c_2/')\n",
    "            )\n",
    "        else:\n",
    "            df_sub.to_parquet(\n",
    "                sub_file\n",
    "            )\n",
    "        del df_sub\n",
    "        gc.collect()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00bcf378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isubfile: 0\n",
      "isubfile: 1\n",
      "isubfile: 2\n",
      "isubfile: 3\n",
      "isubfile: 4\n",
      "isubfile: 5\n",
      "isubfile: 6\n",
      "isubfile: 7\n",
      "isubfile: 8\n",
      "isubfile: 9\n",
      "isubfile: 10\n",
      "isubfile: 11\n",
      "isubfile: 12\n",
      "isubfile: 13\n",
      "isubfile: 14\n",
      "isubfile: 15\n",
      "isubfile: 16\n",
      "isubfile: 17\n",
      "isubfile: 18\n",
      "isubfile: 19\n",
      "isubfile: 20\n",
      "isubfile: 21\n",
      "isubfile: 22\n",
      "isubfile: 23\n",
      "isubfile: 24\n",
      "isubfile: 25\n",
      "isubfile: 26\n",
      "isubfile: 27\n",
      "isubfile: 28\n",
      "isubfile: 29\n",
      "isubfile: 30\n",
      "isubfile: 31\n",
      "isubfile: 32\n",
      "isubfile: 33\n",
      "isubfile: 34\n",
      "isubfile: 35\n",
      "isubfile: 36\n",
      "isubfile: 37\n",
      "isubfile: 38\n",
      "isubfile: 39\n",
      "isubfile: 40\n",
      "isubfile: 41\n",
      "isubfile: 42\n",
      "isubfile: 43\n",
      "isubfile: 44\n",
      "isubfile: 45\n",
      "isubfile: 46\n",
      "isubfile: 47\n",
      "isubfile: 48\n",
      "isubfile: 49\n",
      "isubfile: 50\n",
      "isubfile: 51\n",
      "isubfile: 52\n",
      "isubfile: 53\n",
      "isubfile: 54\n",
      "isubfile: 55\n",
      "isubfile: 56\n",
      "isubfile: 57\n",
      "isubfile: 58\n",
      "isubfile: 59\n",
      "isubfile: 60\n",
      "isubfile: 61\n",
      "isubfile: 62\n",
      "isubfile: 63\n",
      "isubfile: 64\n",
      "isubfile: 65\n",
      "isubfile: 66\n",
      "isubfile: 67\n",
      "isubfile: 68\n",
      "isubfile: 69\n",
      "isubfile: 70\n",
      "isubfile: 71\n",
      "isubfile: 72\n",
      "isubfile: 73\n",
      "isubfile: 74\n",
      "isubfile: 75\n",
      "isubfile: 76\n",
      "isubfile: 77\n",
      "isubfile: 78\n",
      "isubfile: 79\n",
      "isubfile: 80\n",
      "isubfile: 81\n",
      "isubfile: 82\n",
      "isubfile: 83\n",
      "isubfile: 84\n",
      "isubfile: 85\n",
      "isubfile: 86\n",
      "isubfile: 87\n",
      "isubfile: 88\n",
      "isubfile: 89\n",
      "isubfile: 90\n",
      "isubfile: 91\n",
      "isubfile: 92\n",
      "isubfile: 93\n",
      "isubfile: 94\n",
      "isubfile: 95\n",
      "isubfile: 96\n",
      "isubfile: 97\n",
      "isubfile: 98\n",
      "isubfile: 99\n"
     ]
    }
   ],
   "source": [
    "if bl_sub:\n",
    "    for igfold2 in [0,1,2,3,4]:\n",
    "        if ifile==0:\n",
    "            sssfiles = glob.glob('./data_folds/fold_' + str(igfold2) + '/split/sub_c/*.parquet')\n",
    "        else:\n",
    "            sssfiles = glob.glob('./data_folds/fold_' + str(igfold2) + '/split/sub_c_2/*.parquet')\n",
    "        for isubfile, sub_file in enumerate(sssfiles):\n",
    "            print('isubfile: ' + str(isubfile))\n",
    "            df_sub = cudf.read_parquet(sub_file).fillna(-999)\n",
    "            if 'xgb_ca_score' not in df_sub.columns:\n",
    "                df_sub['xgb_ca_score'] = 0.0\n",
    "            \n",
    "            dsub = xgb.DMatrix(data=df_sub[train_cols].values)\n",
    "            for iseed in range(no_seeds):\n",
    "                df_sub['xgb_ca_score'] = df_sub['xgb_ca_score'] + models[iseed].predict(dsub)/no_seeds\n",
    "            if ifile==0:\n",
    "                df_sub.to_parquet(\n",
    "                    sub_file.replace('/sub_c/', '/sub_c_2/')\n",
    "                )\n",
    "            else:\n",
    "                df_sub.to_parquet(\n",
    "                    sub_file\n",
    "                )\n",
    "            del df_sub\n",
    "            gc.collect()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
