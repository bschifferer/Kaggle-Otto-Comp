{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3fd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6cdb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 30 07:58:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    43W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    44W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dd54a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c383e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = False\n",
    "path = '../data/'\n",
    "type_weight = {0:1, 1:6, 2:3}\n",
    "no_files = 5\n",
    "path = '../../data/'\n",
    "    \n",
    "df_type = cudf.DataFrame({\n",
    "    'type': ['clicks', 'carts', 'orders'],\n",
    "    'type_': [0, 1, 2]\n",
    "})\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191ae9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356748\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "sessions = pickle.load(open('./data/sessions_eval.pickle', 'rb'))\n",
    "sess_eval = sessions[0]+sessions[1]\n",
    "print(len(sess_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4fc5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./data/\n",
    "!mkdir -p ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658f63cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(\n",
    "    glob.glob('/otto/data_radek/org/interim/*.parquet')\n",
    ")\n",
    "files_split = [glob.glob('/otto/data_radek/org/test.parquet')] + [glob.glob('./data/xgb_train_x.parquet')] + list_in_chunks(files, no_chunks=len(files)//no_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a9e0999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d5ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 30 07:59:24 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.04   Driver Version: 450.119.04   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    47W / 163W |    646MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    44W / 163W |      0MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95c0a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ec88a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(df, co, prefix, treshhold=2, treshhold_topn=15):\n",
    "    df = df.sort_values([\"session\", \"ts\"])\n",
    "    df['d'] = df.groupby('session').ts.diff()\n",
    "    df.d = (df.d > 60*60*2).astype('int16').fillna(0)\n",
    "    df.d = df.groupby('session').d.cumsum()\n",
    "    df = df.merge(\n",
    "        df.groupby(['session', 'd']).ts.max().reset_index().rename(columns={'ts': 'ts_max_2'}),\n",
    "        how='left',\n",
    "        on=['session', 'd']\n",
    "    )\n",
    "    df['type_w'] = df['type'].isin([0,1])\n",
    "    df = df.merge(\n",
    "        co,\n",
    "        how='left',\n",
    "        on=['aid']\n",
    "    )\n",
    "    df['wgt'] = df['wgt'].fillna(0)\n",
    "    df['wgt_1'] = df['wgt_1']*df['wgt']\n",
    "    df['wgt_2'] = df['wgt_2']*df['wgt']\n",
    "    df['dummy'] = 1\n",
    "    df['t_wgt_1'] = df['wgt_1']*df['type']\n",
    "    df['t_wgt_2'] = df['wgt_2']*df['type']\n",
    "    df['t_dummy'] = df['dummy']*df['type']\n",
    "    df['d_wgt_1'] = df['wgt_1']*(df['d']==0)\n",
    "    df['d_wgt_2'] = df['wgt_2']*(df['d']==0)\n",
    "    df['d_dummy'] = df['dummy']*(df['d']==0)\n",
    "    df['l_dummy'] = df['dummy']*(df['ts']==df['ts_max_2'])\n",
    "    df['l_wgt_1'] = df['wgt_1']*(df['ts']==df['ts_max_2'])\n",
    "    df['l_wgt_2'] = df['wgt_2']*(df['ts']==df['ts_max_2'])\n",
    "\n",
    "    agg = {\n",
    "        'wgt': 'sum',\n",
    "        'dummy': 'sum',\n",
    "        'wgt_1': 'sum',\n",
    "        'wgt_2': 'sum',\n",
    "        't_dummy': 'sum',\n",
    "        't_wgt_1': 'sum',\n",
    "        't_wgt_2': 'sum',\n",
    "        'd_wgt_1': 'sum',\n",
    "        'd_wgt_2': 'sum',\n",
    "        'd_dummy': 'sum',\n",
    "        'l_dummy': 'sum',\n",
    "        'l_wgt_1': 'sum',\n",
    "        'l_wgt_2': 'sum'\n",
    "    }\n",
    "\n",
    "    df = df.groupby(['session', 'cand']).agg(agg)\n",
    "    df.columns = [prefix + '_' + str(x) for x in df.columns]\n",
    "    df = df.reset_index()\n",
    "    return(df)\n",
    "\n",
    "def list_in_chunks(files, no_chunks=10):\n",
    "    out = [[] for _ in range(no_chunks)]\n",
    "    for i, file in enumerate(files):\n",
    "        out[i%no_chunks].append(file)\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b964147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainprefix = 'chris_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eef28114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# 0 #####################\n",
      "356748\n",
      "./data_folds/fold_0/top_40_aids_v115.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v217.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v220.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v226.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v232.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v235.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v239.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v700.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v701.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_0/top_40_aids_v93.parquet\n",
      "train 15\n",
      "sub 15\n",
      "################# 1 #####################\n",
      "356748\n",
      "./data_folds/fold_1/top_40_aids_v115.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v217.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v220.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v226.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v232.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v235.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v239.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v700.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v701.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_1/top_40_aids_v93.parquet\n",
      "train 15\n",
      "sub 15\n",
      "################# 2 #####################\n",
      "356748\n",
      "./data_folds/fold_2/top_40_aids_v115.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v217.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v220.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v226.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v232.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v235.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v239.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v700.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v701.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_2/top_40_aids_v93.parquet\n",
      "train 15\n",
      "sub 15\n",
      "################# 3 #####################\n",
      "356747\n",
      "./data_folds/fold_3/top_40_aids_v115.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v217.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v220.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v226.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v232.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v235.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v239.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v700.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v701.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_3/top_40_aids_v93.parquet\n",
      "train 15\n",
      "sub 15\n",
      "################# 4 #####################\n",
      "356746\n",
      "./data_folds/fold_4/top_40_aids_v115.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v217.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v220.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v226.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v232.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v235.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v239.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v700.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v701.parquet\n",
      "train 15\n",
      "sub 15\n",
      "./data_folds/fold_4/top_40_aids_v93.parquet\n",
      "train 15\n",
      "sub 15\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for igfold in range(5):\n",
    "    print(\"################# \" + str(igfold) + \" #####################\")\n",
    "    sessions = pickle.load(open('./data/sessions_eval.pickle', 'rb'))\n",
    "    if igfold == 0:\n",
    "        sess_eval = sessions[0]+sessions[1]\n",
    "    elif igfold == 1:\n",
    "        sess_eval = sessions[2]+sessions[3]\n",
    "    elif igfold == 2:\n",
    "        sess_eval = sessions[4]+sessions[5]\n",
    "    elif igfold == 3:\n",
    "        sess_eval = sessions[6]+sessions[7]\n",
    "    elif igfold == 4:\n",
    "        sess_eval = sessions[8]+sessions[9]\n",
    "    print(len(sess_eval))\n",
    "    files = sorted(glob.glob('./data_folds/fold_' + str(igfold) + '/top_40_aids_v*'))\n",
    "    for icofile, cofile in enumerate(files):\n",
    "        print(cofile)\n",
    "        prefix = mainprefix + '_' + str(icofile) + '_'\n",
    "        for dataset in ['train', 'sub']:\n",
    "            for treshhold_topn in [15]:\n",
    "                print(dataset, treshhold_topn)\n",
    "                os.system('mkdir -p ./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn))\n",
    "                co = cudf.read_parquet(cofile)\n",
    "                co.columns = ['aid', 'cand', 'wgt']\n",
    "                if dataset == 'train':\n",
    "                    df = cudf.read_parquet('./data/xgb_train_x.parquet')\n",
    "                    df = df[df['session'].isin(sess_eval)]\n",
    "                else:\n",
    "                    df = cudf.read_parquet('../../data/test.parquet')\n",
    "                df = df.merge(\n",
    "                    df_type,\n",
    "                    how='left',\n",
    "                    on='type'\n",
    "                )\n",
    "                df['session'] = df['session'].astype('int32')\n",
    "                df['aid'] = df['aid'].astype('int32')\n",
    "                df.ts = (df.ts/1000).astype('int32')\n",
    "                df.drop(['type'], axis=1, inplace=True)\n",
    "                df = df.rename(columns={'type_': 'type'})\n",
    "                df = df.merge(\n",
    "                    df[['session']].groupby(['session']).size().reset_index().rename(columns={0: 'session_len'}),\n",
    "                    how='left',\n",
    "                    on='session'\n",
    "                )\n",
    "                df = df.merge(\n",
    "                    df[['session', 'ts']].groupby(['session']).max().reset_index().rename(columns={'ts': 'ts_max'}),\n",
    "                    how='left',\n",
    "                    on='session'\n",
    "                )\n",
    "                df = df.sort_values(['session', 'ts'], ascending=[True, False])\n",
    "                df['dummy'] = 1\n",
    "                df['rank'] = df.groupby(['session']).dummy.cumsum()\n",
    "                df.drop(['dummy'], axis=1, inplace=True)\n",
    "                min_val = (2 ** 0.1-1)\n",
    "                max_val = (2 ** 1-1)\n",
    "                df['wgt_1'] = (min_val+(max_val-min_val)*(df['rank']-1)/(df['session_len']))\n",
    "                min_val = (2 ** 0.5-1)\n",
    "                max_val = (2 ** 1-1)\n",
    "                df['wgt_2'] = (min_val+(max_val-min_val)*(df['rank']-1)/(df['session_len']))\n",
    "                if dataset == 'train':\n",
    "                    session_lists = list_in_chunks(df['session'].drop_duplicates().to_pandas().values.tolist(), no_chunks=20)\n",
    "                    out = []    \n",
    "                    for session_list in session_lists:\n",
    "                        df_tmp = df[df['session'].isin(session_list)]\n",
    "                        df_tmp = get_candidates(df_tmp, co, prefix, treshhold=2, treshhold_topn=treshhold_topn)\n",
    "                        out.append(df_tmp)\n",
    "                    del df\n",
    "                    del co\n",
    "                    gc.collect()\n",
    "                    df = cudf.concat(out)\n",
    "                    df['session'] = df['session'].astype('int32')\n",
    "                    df['cand'] = df['cand'].astype('int32')\n",
    "                    df.to_parquet('./data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn) + '/cand.parquet')\n",
    "                    del df\n",
    "                    gc.collect()\n",
    "                else:\n",
    "                    sub_sessions = pickle.load(open('./data/split/sub_sessoins_10.pickle', 'rb'))\n",
    "                    out = []\n",
    "                    tmpfile = './data_folds/fold_' + str(igfold) + '/candidates/' + dataset + '/' + prefix + '_' + str(treshhold_topn) + '/cand.parquet'\n",
    "                    os.system('mkdir -p ' + '/'.join(tmpfile.replace('./data_folds/fold_' + str(igfold) + '/', './data_folds/fold_' + str(igfold) + '/split/').split('/')[:-1]))\n",
    "                    for i, session_list in enumerate(sub_sessions):\n",
    "                        df_tmp = df[df['session'].isin(session_list)]\n",
    "                        df_tmp = get_candidates(df_tmp, co, prefix, treshhold=2, treshhold_topn=treshhold_topn)\n",
    "                        gc.collect()\n",
    "                        df_tmp['session'] = df_tmp['session'].astype('int32')\n",
    "                        df_tmp['cand'] = df_tmp['cand'].astype('int32')\n",
    "                        df_tmp.to_parquet(\n",
    "                            '/'.join(tmpfile.replace('./data_folds/fold_' + str(igfold) + '/', './data_folds/fold_' + str(igfold) + '/split/').split('/')[:-1]) + '/cand_' + str(i) + '.parquet'\n",
    "                        )\n",
    "                        del df_tmp\n",
    "                        gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237122c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150271340"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7513567*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d902a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
